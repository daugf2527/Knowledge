# 自适应三级执行策略框架：侦察 → 录制 → 评估 → 执行

> **文档定位**：描述从"人工首次操作"到"AI 自动生成可执行脚本"的完整工程流水线。  
> 核心思路：**纯协议优先，按防作弊强度逐级降级**。  
> 本文档是主框架设计文档（v1.7）和补丁文档（v1.8）的**上游决策层**，解决"脚本从哪来、走哪条路"的问题。

---

## 总体架构（四阶段流水线）

```
Phase 0: Recon  →  Phase 1: Capture  →  Phase 2: Evaluate  →  Phase 3: Execute
  侦察               录制                  评估                   执行
  识别防作弊工具     人工操作+后台           对照检测矩阵            选 Tier 并执行
                   同步录制 DOM+API流       决定走哪条路
```

```
                              ↓ 决策输出
               ┌──────────────────────────────────┐
               │  Tier 1：纯协议（curl_cffi）       │  最优先
               │  Tier 2：半协议（auth→token→协议） │  次选
               │  Tier 3：纯 DOM 脚本（Playwright） │  兜底
               └──────────────────────────────────┘
```

---

## Phase 0：侦察——识别目标站防作弊工具

> **两轮侦察**：仅靠单次 GET 响应头/Cookie 只能发现约一半工具。中国厂商普遍通过 JS SDK 注入，不在响应头留痕，必须扫描 HTML 源码中的 `<script src>` 域名才能发现。

### 0.1 两轮侦察架构

```
Pass 1（快，~100ms）：curl_cffi GET → 分析响应头 + Set-Cookie
    ↓ 补漏
Pass 2（快，~0ms）：解析同一次响应的 HTML body → 提取 <script src> 域名 + 隐藏字段
    ↓ 合并
最终 detected_tools 列表
```

### 0.2 完整特征签名表

#### 国际厂商

| 防作弊工具 | 响应头特征（Pass 1）| Cookie 特征（Pass 1）| JS/域名特征（Pass 2）|
|---|---|---|---|
| **Cloudflare** | `Server: cloudflare`、`CF-RAY` | `cf_clearance` | `challenges.cloudflare.com` |
| **Akamai Bot Manager** | `X-Akamai-Transformed`、`X-EdgeConnect-MidMile-RTT`、`Akamai-Request-ID` | `abck`、`bm_sz` | `*.akamaiedge.net` sensor JS |
| **DataDome** | `Server: DataDome`、`X-DataDome-CID` | `datadome` | `interstitial.datadome.co` |
| **PerimeterX / HUMAN** | 无（隐蔽） | `_pxvid`、`_px2`、`_pxff_`、`pxcts` | `perimeterx.net`、`px-cdn.net` |
| **Kasada** | `x-kpsdk-ct`、`x-kpsdk-r`、`x-kpsdk-cd` | `x-kpsdk-` | `149e9513-*.js`（混淆 proof.js）|
| **F5 / Shape Security** | `X-WA-Info`（部分） | `TS01`（前缀） | `shape.io` SDK |
| **Imperva (Incapsula)** | `X-Cdn: Incapsula`、`X-Iinfo` | `visid_incap_`、`incap_ses_` | `*.incapdns.net` |
| **reCAPTCHA** | 无 | `_GRECAPTCHA` | `google.com/recaptcha`、`recaptcha.net` |
| **hCaptcha** | 无 | 无 | `hcaptcha.com/1/api.js` |
| **FunCaptcha (Arkose)** | 无 | `fc-` | `arkoselabs.com`、`funcaptcha.com` |

#### 中国厂商（**主要通过 Pass 2 JS 域名识别**）

| 防作弊工具 | Cookie 特征（Pass 1）| JS/域名特征（Pass 2）| 表单隐藏字段（Pass 2）|
|---|---|---|---|
| **极验 GeeTest** | 无 | `static.geetest.com`、`api.geetest.com`、`gcaptcha4.geetest.com` | `geetest_challenge`、`geetest_validate`、`geetest_seccode` |
| **网易易盾** | `ne_`（前缀） | `cstaticdun.126.net`、`dun.163.com`、`necaptcha.nosdn.127.net` | `NECaptchaValidate` |
| **阿里云人机验证** | `_uab_collina`、`cna` | `g.alicdn.com/AWSC/`、`captcha.aliyun.com`、`aegis.alicdn.com` | `nc_csessionid`、`nc_token` |
| **腾讯天御 / TCaptcha** | `pgv_`（前缀） | `ssl.captcha.qq.com`、`t.captcha.qq.com` | `ticket`、`randstr` |
| **数美科技** | 无专属 | `static.portal101.cn`、`static.xiaoyuanwd.com`、`fp.wangsu.com` | 自定义 `_sign`、`deviceId` |
| **顶象 Dingxiang** | `dx_`（前缀） | `static.dingxiang-inc.com`、`fp.dingxiang-inc.com` | `_data_`（混淆） |
| **同盾 TongDun** | `tdid`、`td_`（前缀） | `static.tongdun.net`、`ac.tongdun.net` | `blackbox` |
| **瑞数信息 Ruishu** | `Rsktoken`、`__jsl_clearance` | 无固定域名（RASP 动态混淆，JS 每次请求均变化） | 无（通过动态 JS 计算 token 后注入） |
| **百度云加速** | `BAIDUID`（百度系站点）| `*.bcebos.com`、`*.baidupcs.com` | — |

> **瑞数特殊说明**：瑞数采用 RASP（运行时应用自保护），HTML 源码本身被加密，页面每次请求返回的 JS 均不同，无法用静态域名识别。识别方法：响应 body 为全混淆不可读 HTML、Cookie 含 `Rsktoken`，且 `<script>` 标签内容为 `eval(...)` 形式的大段密文。

> 来源：极验官方文档 https://docs.geetest.com；顶象开放平台 https://open.dingxiang-inc.com；  
> 腾讯 TCaptcha 文档 https://cloud.tencent.com/document/product/1110；  
> 网易易盾 https://dun.163.com/product/captcha-service；  
> Dima Kynal, Medium, Aug 2024；WebAutomation.io, Oct 2025

### 0.3 两轮自动侦察脚本

```python
# tools/recon.py  |  pip install curl_cffi beautifulsoup4
import json, re
from curl_cffi.requests import Session
from bs4 import BeautifulSoup

# ── Pass 1 特征：响应头 + Cookie ──
PASS1_SIGS: dict[str, dict] = {
    "Cloudflare":  {"headers": ["CF-RAY"],                                                   "cookies": ["cf_clearance"],            "server": ["cloudflare"]},
    "Akamai":      {"headers": ["X-Akamai-Transformed","Akamai-Request-ID","X-EdgeConnect-MidMile-RTT"], "cookies": ["abck","bm_sz"],  "server": []},
    "DataDome":    {"headers": ["X-DataDome-CID"],                                           "cookies": ["datadome"],                "server": ["datadome"]},
    "PerimeterX":  {"headers": [],                                                           "cookies": ["_pxvid","_px2","pxcts","_pxff_"], "server": []},
    "Kasada":      {"headers": ["x-kpsdk-ct","x-kpsdk-r"],                                  "cookies": ["x-kpsdk-"],                "server": []},
    "F5_Shape":    {"headers": [],                                                           "cookies": ["TS01"],                    "server": []},
    "Imperva":     {"headers": ["X-Cdn","X-Iinfo"],                                         "cookies": ["visid_incap_","incap_ses_"],"server": ["incapsula"]},
    "Ruishu":      {"headers": [],                                                           "cookies": ["Rsktoken","__jsl_clearance"],"server": []},
    "NetEase_Yidun": {"headers": [],                                                         "cookies": ["ne_"],                     "server": []},
    "Alibaba_CAPTCHA": {"headers": [],                                                       "cookies": ["_uab_collina","cna"],      "server": []},
    "TongDun":     {"headers": [],                                                           "cookies": ["tdid","td_"],              "server": []},
    "Dingxiang":   {"headers": [],                                                           "cookies": ["dx_"],                     "server": []},
    "Tencent_TCaptcha": {"headers": [],                                                      "cookies": ["pgv_"],                    "server": []},
}

# ── Pass 2 特征：HTML 源码中的 <script src> 域名 / 隐藏字段 ──
PASS2_JS_DOMAINS: dict[str, list[str]] = {
    "Cloudflare":       ["challenges.cloudflare.com"],
    "PerimeterX":       ["perimeterx.net","px-cdn.net","px-cloud.net"],
    "Kasada":           ["149e9513"],                          # proof.js 文件名特征
    "F5_Shape":         ["shape.io"],
    "reCAPTCHA":        ["google.com/recaptcha","recaptcha.net/recaptcha"],
    "hCaptcha":         ["hcaptcha.com/1/api.js"],
    "FunCaptcha":       ["arkoselabs.com","funcaptcha.com"],
    "GeeTest":          ["static.geetest.com","api.geetest.com","gcaptcha4.geetest.com"],
    "NetEase_Yidun":    ["cstaticdun.126.net","dun.163.com","necaptcha.nosdn.127.net"],
    "Alibaba_CAPTCHA":  ["g.alicdn.com/AWSC","captcha.aliyun.com","aegis.alicdn.com"],
    "Tencent_TCaptcha": ["ssl.captcha.qq.com","t.captcha.qq.com","cap.qq.com"],
    "Shumei":           ["static.portal101.cn","static.xiaoyuanwd.com","fp.wangsu.com"],
    "Dingxiang":        ["static.dingxiang-inc.com","fp.dingxiang-inc.com"],
    "TongDun":          ["static.tongdun.net","ac.tongdun.net","fm.tongdun.net"],
}

PASS2_HIDDEN_FIELDS: dict[str, list[str]] = {
    "GeeTest":          ["geetest_challenge","geetest_validate","geetest_seccode"],
    "NetEase_Yidun":    ["NECaptchaValidate"],
    "Alibaba_CAPTCHA":  ["nc_csessionid","nc_token"],
    "Tencent_TCaptcha": ["ticket","randstr"],
    "TongDun":          ["blackbox"],
    "Dingxiang":        ["_data_"],
}

def _is_ruishu(html: str) -> bool:
    """瑞数：页面主体为大段 eval(...) 密文，且 <body> 内容极短或全为 script。"""
    soup = BeautifulSoup(html, "html.parser")
    scripts = soup.find_all("script")
    for s in scripts:
        if s.string and len(s.string) > 2000 and s.string.strip().startswith("eval("):
            return True
    return False

def recon(url: str) -> dict:
    with Session(impersonate="chrome124") as s:
        resp = s.get(url, timeout=15, allow_redirects=True)

    html      = resp.text
    h_lower   = {k.lower(): v.lower() for k, v in resp.headers.items()}
    c_str     = " ".join(resp.cookies.keys()).lower()
    server    = h_lower.get("server", "")
    detected  = set()

    # ── Pass 1：响应头 + Cookie ──
    for tool, sigs in PASS1_SIGS.items():
        if (any(h.lower() in h_lower     for h in sigs["headers"]) or
            any(c.lower() in c_str       for c in sigs["cookies"]) or
            any(sv.lower() in server     for sv in sigs["server"])):
            detected.add(tool)

    # ── Pass 2a：HTML 源码 script src 域名扫描 ──
    soup         = BeautifulSoup(html, "html.parser")
    script_srcs  = " ".join(
        (tag.get("src") or "") for tag in soup.find_all("script")
    ).lower()
    inline_text  = " ".join(
        (tag.string or "") for tag in soup.find_all("script") if not tag.get("src")
    ).lower()

    for tool, domains in PASS2_JS_DOMAINS.items():
        if any(d.lower() in script_srcs or d.lower() in inline_text for d in domains):
            detected.add(tool)

    # ── Pass 2b：隐藏字段扫描 ──
    hidden_names = " ".join(
        (tag.get("name") or "") for tag in soup.find_all("input", {"type": "hidden"})
    ).lower()
    for tool, fields in PASS2_HIDDEN_FIELDS.items():
        if any(f.lower() in hidden_names for f in fields):
            detected.add(tool)

    # ── Pass 2c：瑞数特征检测 ──
    if _is_ruishu(html):
        detected.add("Ruishu")

    result = {
        "url":      url,
        "status":   resp.status_code,
        "detected": sorted(detected),
        "headers":  dict(resp.headers),
        "cookies":  dict(resp.cookies),
    }
    print(json.dumps(result, indent=2, ensure_ascii=False))
    return result

if __name__ == "__main__":
    import sys
    recon(sys.argv[1])
```

### 0.4 侦察结果持久化

```sql
CREATE TABLE IF NOT EXISTS site_recon (
    id           INTEGER PRIMARY KEY AUTOINCREMENT,
    domain       TEXT UNIQUE,
    antibot_tool TEXT,          -- 逗号分隔，如 "GeeTest,Cloudflare"
    raw_headers  TEXT,          -- JSON
    raw_cookies  TEXT,          -- JSON
    recon_at     TEXT DEFAULT (datetime('now')),
    tier_verdict TEXT           -- 评估后填写：tier1 | tier2 | tier3
);
```

---

## Phase 1：人工录制——四轨同步捕获

**目标**：人工完整执行一遍目标任务，后台四轨同步录制，消除因果链断裂和动态 Token 盲区。

### 1.1 双轨的盲区（为何需要四轨）

| 盲区 | 问题 | 典型受害场景 |
|---|---|---|
| **因果链断裂** | HAR 与 DOM ops 是独立流，AI 无法知道"哪个点击触发了哪个 API" | 所有场景，AI 生成脚本时只能猜依赖关系 |
| **动态 Token 不可见** | CSRF token / hidden nonce 嵌在 HTML 里，HAR 有请求但不知"值从哪来" | 有 CSRF 保护的登录/表单提交 |
| **Storage 变更丢失** | `localStorage` 写入只在结束时抓一次，中间状态全丢 | SPA（把 token 存 localStorage 的站点） |
| **WebSocket 盲区** | Playwright `recordHar` 对 WS 帧支持差 | 实时应用、部分 Web3 dApp |

### 1.2 四轨录制方案

```python
# tools/capture.py  |  pip install playwright
import asyncio, json, pathlib
from playwright.async_api import async_playwright

CAPTURE_DIR = pathlib.Path("capture")

async def record_session(target_url: str):
    CAPTURE_DIR.mkdir(exist_ok=True)
    har_path  = str(CAPTURE_DIR / "session.har")
    ops_path  = CAPTURE_DIR / "dom_ops.jsonl"
    mut_path  = CAPTURE_DIR / "dom_mutations.jsonl"
    stor_path = CAPTURE_DIR / "storage_log.jsonl"

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        context = await browser.new_context(
            record_har_path=har_path,      # 轨道①：HTTP 网络流量（Playwright 原生）
            record_har_url_filter="**",
        )
        page = await context.new_page()

        # ── 轨道②：用户 DOM 操作事件（点击/输入/滚动）──
        await page.add_init_script("""
            window.__domOps = [];
            ['click','input','change','scroll','keydown'].forEach(evt => {
                document.addEventListener(evt, (e) => {
                    const el = e.target;
                    window.__domOps.push({
                        ts: Date.now(), type: evt,
                        tag: el.tagName, id: el.id,
                        cls: el.className,
                        ariaLabel: el.getAttribute('aria-label') || '',
                        testId:    el.getAttribute('data-testid') || '',
                        value: (evt==='input'||evt==='change') ? el.value : undefined,
                    });
                }, true);
            });
        """)

        # ── 轨道③：DOM Mutation Observer（追踪 API 响应后页面结构变化）──
        await page.add_init_script("""
            window.__mutations = [];
            const obs = new MutationObserver(records => {
                records.forEach(r => {
                    window.__mutations.push({
                        ts:       Date.now(),
                        type:     r.type,
                        target:   r.target.id || r.target.className || r.target.tagName,
                        added:    r.addedNodes.length,
                        removed:  r.removedNodes.length,
                        attrName: r.attributeName,
                        attrVal:  r.attributeName ? r.target.getAttribute(r.attributeName) : undefined,
                    });
                });
            });
            document.addEventListener('DOMContentLoaded', () => {
                obs.observe(document.body, {childList:true, subtree:true, attributes:true});
            });
        """)

        # ── 轨道④：Storage 变更监听（实时捕获 token/nonce 写入时机）──
        await page.add_init_script("""
            window.__storageLog = [];
            ['localStorage','sessionStorage'].forEach(store => {
                const _set = window[store].setItem.bind(window[store]);
                window[store].setItem = (k, v) => {
                    window.__storageLog.push({ts: Date.now(), store, op:'set', key:k, value:v});
                    _set(k, v);
                };
                const _rm = window[store].removeItem.bind(window[store]);
                window[store].removeItem = (k) => {
                    window.__storageLog.push({ts: Date.now(), store, op:'remove', key:k});
                    _rm(k);
                };
            });
        """)

        await page.goto(target_url)
        print("⏳ 请人工完成所有操作，完成后导航至 about:blank 结束录制...")
        await page.wait_for_url("about:blank", timeout=600_000)

        # 导出三条 JS 轨道
        ops   = await page.evaluate("window.__domOps")
        muts  = await page.evaluate("window.__mutations")
        storl = await page.evaluate("window.__storageLog")

        def write_jsonl(path, rows):
            with open(path, "w", encoding="utf-8") as f:
                for row in rows:
                    f.write(json.dumps(row, ensure_ascii=False) + "\n")

        write_jsonl(ops_path,  ops)
        write_jsonl(mut_path,  muts)
        write_jsonl(stor_path, storl)

        await context.close()   # 触发 HAR 文件落盘
        await browser.close()
        print(f"✅ 四轨录制完成\n  ① HAR      → {har_path}\n  ② DOM ops  → {ops_path}"
              f"\n  ③ Mutations→ {mut_path}\n  ④ Storage  → {stor_path}")

asyncio.run(record_session("https://target-site.com"))
```

### 1.3 后处理：四轨合并为统一时间轴

AI 生成脚本时优先消费 `timeline.jsonl`，因果链（点击 → API 请求 → DOM 变化）在同一时间轴上一目了然。

```python
# tools/merge_timeline.py
import json, pathlib
from datetime import datetime, timezone

CAPTURE = pathlib.Path("capture")

def iso_to_ms(iso: str) -> int:
    dt = datetime.fromisoformat(iso.replace("Z", "+00:00"))
    return int(dt.timestamp() * 1000)

def merge_timeline():
    timeline = []

    # 轨道①：HAR entries → 统一格式
    with open(CAPTURE / "session.har") as f:
        entries = json.load(f)["log"]["entries"]
    for e in entries:
        ts_ms = iso_to_ms(e["startedDateTime"])
        timeline.append({
            "ts_ms": ts_ms, "kind": "request",
            "method": e["request"]["method"],
            "url":    e["request"]["url"],
            "status": e["response"]["status"],
            "req_body": e["request"].get("postData", {}).get("text", ""),
            "resp_body": e["response"]["content"].get("text", "")[:500],  # 截断
        })

    # 轨道②③④：直接读 JSONL
    for fname, kind in [("dom_ops.jsonl","dom_op"), ("dom_mutations.jsonl","mutation"),
                        ("storage_log.jsonl","storage")]:
        path = CAPTURE / fname
        if not path.exists(): continue
        with open(path) as f:
            for line in f:
                row = json.loads(line)
                row["kind"] = kind
                timeline.append(row)

    timeline.sort(key=lambda x: x.get("ts_ms", x.get("ts", 0)))

    with open(CAPTURE / "timeline.jsonl", "w", encoding="utf-8") as f:
        for row in timeline:
            f.write(json.dumps(row, ensure_ascii=False) + "\n")

    print(f"✅ 合并完成：{len(timeline)} 条事件 → capture/timeline.jsonl")

if __name__ == "__main__":
    merge_timeline()
```

### 1.4 产出物

```
capture/
  session.har          # ① HTTP 网络流量（含请求/响应头、Body）
  dom_ops.jsonl        # ② 用户 DOM 操作事件（点击/输入/滚动）
  dom_mutations.jsonl  # ③ DOM 结构变化（API 响应后页面如何更新）
  storage_log.jsonl    # ④ localStorage/sessionStorage 写入时序
  timeline.jsonl       # 四轨合并按时间排序的统一事件流（AI 的主输入）
```

**`timeline.jsonl` 片段示意**（可见完整因果链）：
```jsonl
{"ts_ms":1708339810000,"kind":"dom_op","type":"click","tag":"BUTTON","ariaLabel":"登录"}
{"ts_ms":1708339810050,"kind":"request","method":"POST","url":"/api/auth/login","status":200,"resp_body":"{\"token\":\"eyJ...\"}"}
{"ts_ms":1708339810080,"kind":"storage","store":"localStorage","op":"set","key":"authToken","value":"eyJ..."}
{"ts_ms":1708339810120,"kind":"mutation","type":"childList","target":"dashboard-container","added":1,"removed":0}
```

> 来源：Playwright docs, "Mock APIs / recordHar", https://playwright.dev/docs/mock；  
> MDN, "MutationObserver API", https://developer.mozilla.org/en-US/docs/Web/API/MutationObserver

---

## Phase 2：可行性评估——三步综合决策

> 评估分三步：**① 通用检测维度扫描 → ② 逐工具能力分级 → ③ 金丝雀主动探测**。  
> 静态推断可能高估防护强度（把 Tier 2 误判为 Tier 3），金丝雀探测是唯一确认手段。

### 2.1 十二维检测矩阵（通用层）

| # | 检测维度 | 检测内容 | curl_cffi 能否应对 | 备注 |
|---|---|---|---|---|
| 1 | **TLS / JA3 层** | cipher suite 顺序、JA3/JA4 hash | ✅ `impersonate=chrome124` | curl_cffi 完整伪装 |
| 2 | **HTTP/2 指纹层** | SETTINGS 帧参数、Header 伪头部顺序、ALPN | ✅ 原生 HTTP/2 | curl_cffi 原生 |
| 3 | **请求头一致性** | UA、Sec-CH-UA、Accept-Language、Header 顺序 | ✅ 手动构造 | 必须与 UA 版本一致 |
| 4 | **IP 声誉层** | DC IP vs 住宅 IP vs 移动 IP，ASN 数据库 | ⚠️ 配合住宅代理 | DC IP 是最常见封禁原因 |
| 5 | **JS 环境指纹层** | Canvas/WebGL/Audio hash、navigator 属性、硬件信息 | ❌ 无 JS 执行 | 需浏览器 |
| 6 | **JS Challenge 层** | 5s 挑战、proof.js、sensor data 计算 | ❌ 需执行混淆 JS | 需浏览器 |
| 7 | **行为遥测层** | 鼠标轨迹、滚动深度、点击分布、停留时长 | ❌ 纯协议无行为信号 | 需浏览器 |
| 8 | **CAPTCHA 层** | 滑块/点选/语义/不可见打分 | ⚠️ 需外部 Solver API | 可配合解题服务 |
| 9 | **Cookie 绑定层** | cookie 是否绑定请求 IP 或 UA（IP Pinning）| ⚠️ Tier 2 session 导出后需同 IP | Cloudflare Enterprise 有此能力 |
| 10 | **账号行为分析层** | 跨请求账号级别行为异常（速度、顺序、时间） | ❌ 协议层不能模拟人类节奏 | 需加随机延迟或浏览器 |
| 11 | **每请求 Token 验证** | 每次 API 请求均需动态 token（DataDome / Kasada）| ❌ 无法预计算 | 必须浏览器实时生成 |
| 12 | **无头浏览器检测** | 检测 Playwright/Puppeteer 特征（CDP leak、属性缺失）| ⚠️ Tier 3 需配 stealth patch | 见补丁 v1.8 §2.x |

> 来源：Scrapfly, "Bypass Akamai", Sep 2025；arxiv:2602.09606, Feb 2026；  
> Incolumitas.com, "Detecting Headless Browsers", 2024

---

### 2.2 各工具详细能力分级与绕过方案

> **关键差异**：国外工具多为"实时拦截"（触发即 block），国内风控工具（数美/顶象/同盾）多为"**打分+标记**"（不直接 block，而是把风险分传给业务层决策）。后者在住宅 IP 下正常请求往往打分较低，不会触发拦截，可降一个 Tier 处理。

#### 国际厂商

| 工具 | 验证频率 | 主要检测手段 | Session 可复用？ | 推荐 Tier | 绕过方式 |
|---|---|---|---|---|---|
| **Cloudflare（Free/Pro）** | 一次性（5s challenge） | JS challenge + TLS | ✅ `cf_clearance` 30min~24h | Tier 2 | 浏览器过一次 challenge → 导出 cookie → curl_cffi 复用 |
| **Cloudflare Bot Management（Enterprise）** | 每请求 ML 打分 | 行为遥测 + JS + TLS | ❌ 每请求均需评分 | Tier 3 | 全程 Playwright + stealth |
| **Akamai（基础配置）** | 一次性 + 周期刷新 | sensor data JS + TLS | ⚠️ `abck` 1h 内可复用 | Tier 2 | 浏览器执行 sensor → 导出 cookie → 1h 内协议复用 |
| **Akamai（高敏感配置）** | 每请求持续采集 | 深度行为遥测 | ❌ 持续采集无法伪造 | Tier 3 | 全程 Playwright |
| **DataDome** | 每请求 ML 打分 | 实时行为分析 + IP | ❌ 无法复用 | Tier 3 | 全程 Playwright；商业级需 Capsolver/2captcha |
| **PerimeterX / HUMAN** | 每请求隐形遥测 | 行为指纹（不可见） | ❌ 无法复用 | Tier 3 | 全程 Playwright + 深度 stealth |
| **Kasada** | 每请求 proof.js | 混淆 JS 计算 token | ❌ 每次均需计算 | Tier 3 | 全程 Playwright（需 JS 执行） |
| **F5 / Shape Security** | 企业级持续遥测 | 多维行为 + 设备指纹 | ❌ | Tier 3 | 全程 Playwright；极难自动化 |
| **Imperva** | cookie 周期刷新 | JS challenge + cookie | ⚠️ 周期性刷新 | Tier 2 | 同 Cloudflare 模式 |
| **reCAPTCHA v2** | 按需触发 | 图片识别 | ✅ 解完即可 | Tier 2 | 2captcha / CapSolver API |
| **reCAPTCHA v3** | 每页面隐形打分 | 行为轨迹 | ⚠️ 分数衰减 | Tier 2~3 | 住宅 IP + 人工行为可保高分 |
| **hCaptcha** | 按需触发 | 图片选择 | ✅ 解完即可 | Tier 2 | CapSolver / NexCaptcha API |
| **FunCaptcha（Arkose）** | 按需触发 | 游戏类挑战 | ✅ | Tier 2 | CapSolver API（费用较高） |

#### 中国厂商（打分策略 vs 拦截策略）

| 工具 | 拦截方式 | 主要检测手段 | Session 可复用？ | 推荐 Tier | 关键注意 |
|---|---|---|---|---|---|
| **极验 GeeTest v3** | 触发时展示滑块 | 滑动轨迹分析 | ✅ token 一次有效 | Tier 2 | 需接 CAPTCHA Solver（轨迹算法已逆向，成本低） |
| **极验 GeeTest v4** | 自适应（无感/滑块/点选）| 行为 + 语义 | ✅ | Tier 2 | 需 CapSolver / 2captcha GeeTest v4 接口 |
| **极验自适应高敏感** | 全程行为打分 | 深度行为遥测 | ❌ | Tier 3 | 行为分低于阈值时展示强 CAPTCHA |
| **网易易盾** | 触发时展示滑块/旋转 | 轨迹 + 设备指纹 | ✅ token 一次有效 | Tier 2 | 接 CapSolver 易盾接口 |
| **阿里云人机验证** | 触发时展示滑块 | 轨迹 + `_uab_collina` | ✅ | Tier 2 | `_uab_collina` 为设备指纹 cookie，住宅 IP 下通过率高 |
| **腾讯天御 / TCaptcha** | 触发时展示滑块/图片 | 轨迹 + 账号画像 | ✅ `ticket` 一次有效 | Tier 2 | 接 CapSolver 腾讯验证码接口 |
| **数美科技** | **打分+标记（不直接 block）**| 设备指纹 + 行为 | ✅ session 持续有效 | **Tier 1/2** | 住宅 IP 下风险分通常可接受；业务层决策是否 block |
| **顶象 Dingxiang** | **打分+标记（不直接 block）**| 设备指纹 + 环境检测 | ✅ | **Tier 1/2** | 同数美；注意 `_data_` 隐藏字段需从 HTML 提取 |
| **同盾 TongDun** | **打分+标记（不直接 block）**| 设备指纹（`blackbox`）| ✅ | **Tier 1/2** | `blackbox` 值需从页面 JS 执行结果获取，可预先用浏览器提取后复用 |
| **瑞数信息 Ruishu** | 每页 RASP 动态混淆 | 动态 JS + cookie 绑定 | ❌ 每次请求 JS 均变化 | **Tier 3** | 最难绕过的国内工具，连 Playwright 也需额外处理 |

---

### 2.3 金丝雀探测——主动验证纯协议是否可行

> **核心思路**：静态推断可能保守（例如 Cloudflare Free 判 Tier 2，但实际直接 Tier 1 就能过）。  
> 用金丝雀请求对**实际目标 API 端点**（而非首页）探测，以实测结果校正 Tier。

```python
# tools/canary_probe.py  |  pip install curl_cffi
import asyncio
from curl_cffi.requests import AsyncSession

CANARY_VERDICT = {
    200: "tier1",      # 直接通过，纯协议可行
    201: "tier1",
    302: "tier1",      # 登录后重定向，正常
    401: "tier1",      # 认证失败但请求已到达业务层（非防作弊拦截）
    403: "tier2",      # 访问被拒，可能需要浏览器 auth 获取合法 session
    429: "tier2",      # 频率限制，换 IP 或降速后可尝试
    503: "tier3",      # challenge 页，强防作弊介入
    # 其他 4xx/5xx → 保守判 tier2
}

async def canary_probe(api_endpoint: str, account: dict,
                        test_payload: dict | None = None) -> dict:
    """
    用 curl_cffi 向目标 API 发一次最小化探测请求。
    返回实测 HTTP 状态码 + 响应特征 + 最终 Tier 建议。
    """
    async with AsyncSession(
        impersonate="chrome124",
        proxies={"https": account["proxy"]["endpoint"]},
    ) as s:
        try:
            if test_payload:
                r = await s.post(api_endpoint, json=test_payload, timeout=10)
            else:
                r = await s.get(api_endpoint, timeout=10)
        except Exception as e:
            return {"status": -1, "error": str(e), "verdict": "tier2"}

    body_lower = r.text[:500].lower()

    # 响应体特征优先于状态码（有些工具返回 200 但 body 是 challenge）
    if any(k in body_lower for k in ["datadome","captcha","challenge","verify human",
                                      "x-kpsdk","perimeterx","px-blocked"]):
        verdict = "tier3"
    elif any(k in body_lower for k in ["cf_clearance","just a moment"]):
        verdict = "tier2"
    else:
        verdict = CANARY_VERDICT.get(r.status_code, "tier2")

    return {
        "endpoint":    api_endpoint,
        "status":      r.status_code,
        "body_sample": r.text[:200],
        "verdict":     verdict,
    }
```

**探测端点选取原则**：

| 目标任务 | 探测端点 | 探测 payload |
|---|---|---|
| 注册账号 | `/api/auth/register` 或 `/api/signup` | `{"email":"test@test.com"}` |
| 登录 | `/api/auth/login` 或 `/api/session` | `{"email":"x","password":"x"}` |
| 核心业务（checkin 等）| 从 HAR 录制中提取的实际端点 | 无 token 空请求（只看能否到达业务层）|

---

### 2.4 CAPTCHA Solver 集成（Tier 2 CAPTCHA 类工具必备）

| CAPTCHA 类型 | 推荐 Solver 服务 | API 方式 | 参考价格 |
|---|---|---|---|
| GeeTest v3（滑块） | CapSolver、2captcha、NextCaptcha | `gt` + `challenge` 参数 | ~$1/1000 次 |
| GeeTest v4 | CapSolver | `captcha_id` 参数 | ~$2/1000 次 |
| 网易易盾 | CapSolver | 易盾专项接口 | ~$1.5/1000 次 |
| 腾讯 TCaptcha | CapSolver、2captcha | `appid` 参数 | ~$1/1000 次 |
| hCaptcha | 2captcha、CapSolver | `sitekey` 参数 | ~$2/1000 次 |
| reCAPTCHA v2 | 2captcha、AntiCaptcha | `k` 参数 | ~$1/1000 次 |
| reCAPTCHA v3 | CapSolver | `action` + min score | ~$2/1000 次 |
| FunCaptcha（Arkose）| CapSolver | `publicKey` | ~$3/1000 次 |

> 来源：CapSolver 价格页 https://www.capsolver.com/pricing；2captcha 价格页 https://2captcha.com/2captcha-api

---

### 2.5 综合 Tier 决策逻辑

```python
# tools/tier_evaluator.py（完整版）

# 静态 Tier 映射（保守估计，金丝雀可降级）
TOOL_TIER_STATIC: dict[str, str] = {
    # 国际工具
    "Cloudflare":          "tier2",   # Enterprise Bot Management → tier3（需人工判断）
    "Akamai":              "tier2",   # 高敏感配置 → tier3
    "DataDome":            "tier3",
    "PerimeterX":          "tier3",
    "Kasada":              "tier3",
    "F5_Shape":            "tier3",
    "Imperva":             "tier2",
    "reCAPTCHA":           "tier2",   # v3 高分要求 → tier3
    "hCaptcha":            "tier2",
    "FunCaptcha":          "tier2",
    # 中国工具
    "GeeTest":             "tier2",   # 自适应高敏感 → tier3
    "NetEase_Yidun":       "tier2",
    "Alibaba_CAPTCHA":     "tier2",
    "Tencent_TCaptcha":    "tier2",
    "Shumei":              "tier1",   # 打分型，住宅 IP 通常可行
    "Dingxiang":           "tier1",   # 打分型
    "TongDun":             "tier2",   # blackbox 字段需预先提取
    "Ruishu":              "tier3",   # RASP 动态混淆，最难
}

NEEDS_CAPTCHA_SOLVER: set[str] = {
    "GeeTest","NetEase_Yidun","Alibaba_CAPTCHA","Tencent_TCaptcha",
    "reCAPTCHA","hCaptcha","FunCaptcha",
}

def static_tier(detected: list[str]) -> str:
    order = {"tier1": 1, "tier2": 2, "tier3": 3}
    tiers = [TOOL_TIER_STATIC.get(t, "tier3") for t in detected]
    return max(tiers, key=lambda t: order[t]) if tiers else "tier1"

def needs_captcha_solver(detected: list[str]) -> bool:
    return bool(set(detected) & NEEDS_CAPTCHA_SOLVER)

async def full_evaluate(url: str, account: dict,
                         detected: list[str], api_endpoint: str) -> dict:
    """
    三步综合评估：
    1. 静态推断（基于侦察结果）
    2. 金丝雀主动探测（实测目标 API）
    3. 综合两者，取保守值（静态推断 ≥ 金丝雀实测）
    """
    from tools.canary_probe import canary_probe

    s_tier   = static_tier(detected)
    canary   = await canary_probe(api_endpoint, account)
    c_tier   = canary["verdict"]

    order    = {"tier1": 1, "tier2": 2, "tier3": 3}
    # 金丝雀结果可降级静态推断（实测比预期更宽松），但不能提升
    final    = max([s_tier, c_tier], key=lambda t: order[t])

    return {
        "static_tier":   s_tier,
        "canary_tier":   c_tier,
        "final_tier":    final,
        "needs_solver":  needs_captcha_solver(detected),
        "canary_detail": canary,
    }
```

### 2.6 决策树（含金丝雀）

```
Phase 0 侦察 → detected_tools
    │
    ├─ 静态 Tier 推断（TOOL_TIER_STATIC 取最高）
    │
    ├─ 金丝雀探测（curl_cffi 打实际 API 端点）
    │       ├─ 200/401 → canary = tier1（协议可达业务层）
    │       ├─ 403     → canary = tier2（需合法 session）
    │       └─ 503/challenge body → canary = tier3
    │
    ├─ 综合：final_tier = max(static, canary)
    │
    ├─ final = tier1 → 纯协议（curl_cffi 全程）
    ├─ final = tier2 → 半协议（浏览器 auth → 导出 session → curl_cffi）
    │              + 若 needs_solver → 集成 CAPTCHA Solver
    └─ final = tier3 → 全程 Playwright + stealth + human_move_and_click
```

---

## Phase 3：三级执行策略

### 三级能力对比

| 维度 | Tier 1（纯协议）| Tier 2（半协议）| Tier 3（全 DOM）|
|---|---|---|---|
| **内存/账号** | ~2 MB | auth 阶段 ~150 MB，业务阶段 ~2 MB | ~300 MB 常驻 |
| **最大并发** | 数百（受代理限制）| 5~20（auth 串行，业务并发）| 4~8（受 CPU/内存限制）|
| **执行速度** | 100~500 ms/任务 | auth 20~60 s + 业务 100 ms | 30~120 s/任务 |
| **JS Challenge** | ❌ | ✅ 浏览器过关后复用 | ✅ 全程浏览器 |
| **行为分析** | ❌ | ❌（业务阶段）| ✅ human_move_and_click |
| **降级触发** | 连续 403 / challenge body | 浏览器 auth 失败 ≥2 次 | 最终兜底，不降级 |

---

### Tier 1：纯协议模式

**适用**：无防作弊；或仅 IP/频率限制；或数美/顶象等打分型工具（住宅 IP 风险分可接受）。

**缺失项修复**：

| 问题 | 解决方案 |
|---|---|
| CSRF token 漏传 | 登录前先 GET 登录页，从 HTML hidden input 提取一次性 token |
| 无重试 | 指数退避，最多 3 次；429 额外等待 |
| 无降级触发 | 连续 2 次 403 且 body 含 challenge 关键词 → 返回 `_tier_escalate=tier2` |
| 请求节奏机械 | 每步 0.5~2 s 随机延迟，防账号行为异常 |

```python
# plugins/tier1_protocol.py  |  pip install curl_cffi beautifulsoup4
import asyncio, random, logging
from curl_cffi.requests import AsyncSession
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)
DOWNGRADE_KW = ["captcha","challenge","blocked","verify human","x-kpsdk","just a moment"]

def _should_downgrade(status: int, body: str) -> bool:
    return status in (403, 503) and any(k in body[:500].lower() for k in DOWNGRADE_KW)

async def _fetch_csrf(s: AsyncSession, login_url: str) -> str | None:
    r = await s.get(login_url, timeout=10)
    soup = BeautifulSoup(r.text, "html.parser")
    for name in ["_csrf","csrf_token","authenticity_token","__RequestVerificationToken"]:
        tag = soup.find("input", {"name": name})
        if tag:
            return tag.get("value")
    meta = soup.find("meta", {"name": "csrf-token"})
    return meta.get("content") if meta else None

async def run_tier1(task: dict, account: dict, site: str,
                    max_retries: int = 3) -> dict:
    downgrade_n = 0
    for attempt in range(max_retries):
        try:
            async with AsyncSession(
                impersonate="chrome124",
                proxies={"https": account["proxy"]["endpoint"]},
            ) as s:
                csrf = await _fetch_csrf(s, f"{site}/login")
                await asyncio.sleep(random.uniform(0.8, 2.0))

                body = {"email": account["email"], "password": account["password"]}
                if csrf:
                    body["_csrf"] = csrf

                r = await s.post(f"{site}/api/auth/login", json=body, headers={
                    "Origin": site, "Referer": f"{site}/login",
                    "Sec-Fetch-Site": "same-origin", "Sec-Fetch-Mode": "cors",
                }, timeout=15)

                if _should_downgrade(r.status_code, r.text):
                    downgrade_n += 1
                    if downgrade_n >= 2:
                        return {"_tier_escalate": "tier2",
                                "reason": f"403/challenge ×{downgrade_n}"}
                    await asyncio.sleep(random.uniform(3, 8))
                    continue

                r.raise_for_status()
                token = (r.json().get("token") or r.json().get("access_token")
                         or r.cookies.get("session"))

                await asyncio.sleep(random.uniform(0.5, 1.5))

                r2 = await s.post(f"{site}/api/task/checkin",
                    json={"task_id": task["id"]},
                    headers={"Authorization": f"Bearer {token}"}, timeout=15)

                if _should_downgrade(r2.status_code, r2.text):
                    return {"_tier_escalate": "tier2", "reason": "business API blocked"}

                return {"status": "ok", "data": r2.json(), "tier": "tier1"}

        except Exception as e:
            wait = 2 ** attempt + random.uniform(0, 1)
            logger.warning("Tier1 attempt %d failed: %s, retry in %.1fs", attempt, e, wait)
            await asyncio.sleep(wait)

    return {"_tier_escalate": "tier2", "reason": "max retries exhausted"}
```

**curl_cffi 指纹伪装范围**（来源：https://curl-cffi.readthedocs.io/）：

| 维度 | 支持 |
|---|---|
| JA3/JA4 TLS 握手指纹 | ✅ cipher suite + extension 顺序 |
| HTTP/2 SETTINGS 帧 | ✅ HEADER_TABLE_SIZE、INITIAL_WINDOW_SIZE 等 |
| HTTP/2 伪头部顺序 | ✅ `:method :path :scheme :authority` |
| ALPN、HTTP/3、WebSocket | ✅（HTTP/3 需 v0.12.0+）|

---

### Tier 2：半协议模式

**适用**：Cloudflare / Akamai / Imperva 等 CDN 级保护；GeeTest / 易盾 / TCaptcha 等 CAPTCHA 类工具。  
**策略**：浏览器只负责 auth（过 JS Challenge / CAPTCHA），拿到 cookie/token 后立即交棒 `curl_cffi`；**Session 失效时运行时自动续期，不重启整个任务**。

#### Session 生命周期

```
调度器触发执行
    │
    ├─ DB session_expires_at > now+5min? ─→ 是 → 直接注入 curl_cffi
    │                                        否 → browser_auth() → 存 DB
    │
    ↓ 业务接口执行中
    ├─ 返回 401/403 + challenge 特征?
    │   └─ 是 → session_refresh()
    │           ├─ 成功 → 重试业务接口
    │           └─ 失败 ≥2 次 → _tier_escalate=tier3
    │
    └─ 正常 → 更新 session_expires_at，返回结果
```

#### Session 有效期参考

| Cookie | 典型 TTL | 失效信号 | 处理 |
|---|---|---|---|
| `cf_clearance` | 30 min ~ 24 h | 403 + "Just a moment" | 重新 browser_auth |
| `abck`（Akamai）| 1 h | 403 + akamai 特征 body | 重新 browser_auth |
| `geetest_validate` | 一次性 | 业务接口返回 CAPTCHA 错误 | 重新 solver |
| `ticket`（TCaptcha）| 一次性 | 4xx + ticket invalid | 重新 solver |

```python
# plugins/tier2_semi_protocol.py
import asyncio, random, logging
from datetime import datetime, timezone, timedelta
from playwright.async_api import async_playwright, Page
from curl_cffi.requests import AsyncSession

logger = logging.getLogger(__name__)
SESSION_MARGIN = timedelta(minutes=5)
CHALLENGE_KW   = ["just a moment","cf_clearance","challenge","verify","captcha"]

# ── CAPTCHA Solver 钩子（按需替换为实际 CapSolver / 2captcha 调用）──
async def _solve_captcha_if_present(page: Page, site: str) -> None:
    gt        = await page.evaluate("window.captcha_gt || null")
    challenge = await page.evaluate("window.captcha_challenge || null")
    if not (gt and challenge):
        return
    import httpx
    resp = httpx.post("https://api.capsolver.com/createTask", json={
        "clientKey": "YOUR_KEY",
        "task": {"type": "GeeTestTaskProxyLess",
                 "websiteURL": site, "gt": gt, "challenge": challenge},
    }, timeout=30).json()
    logger.info("CAPTCHA submitted, taskId=%s", resp.get("taskId"))
    # 轮询 getTaskResult 并将 validate/seccode 填回表单（站点具体实现）

async def browser_auth(account: dict, site: str,
                        headless: bool = True) -> dict:
    """
    浏览器完成登录：headless=True 用于自动化，调试时传 False。
    返回 {cookies, token, expires_at}。
    """
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=headless)
        ctx = await browser.new_context(
            proxy={"server": account["proxy"]["endpoint"]},
            user_agent=account.get("user_agent", ""),
        )
        page = await ctx.new_page()
        await page.goto(f"{site}/login", wait_until="networkidle", timeout=30_000)
        await asyncio.sleep(random.uniform(0.5, 1.5))
        await page.fill('[name="email"]',    account["email"])
        await asyncio.sleep(random.uniform(0.3, 0.8))
        await page.fill('[name="password"]', account["password"])
        await asyncio.sleep(random.uniform(0.3, 0.8))
        await _solve_captcha_if_present(page, site)
        await page.click('[type="submit"]')
        await page.wait_for_url(f"{site}/dashboard", timeout=45_000)
        cookies = await ctx.cookies()
        token   = await page.evaluate(
            "localStorage.getItem('authToken') || localStorage.getItem('token') || ''")
        await browser.close()

    return {
        "cookies":    {c["name"]: c["value"] for c in cookies},
        "token":      token,
        "expires_at": (datetime.now(timezone.utc) + timedelta(hours=1)).isoformat(),
    }

def _session_valid(account: dict) -> bool:
    exp = account.get("session_expires_at")
    if not exp:
        return False
    return datetime.fromisoformat(exp) > datetime.now(timezone.utc) + SESSION_MARGIN

async def run_tier2(task: dict, account: dict, site: str,
                    state_manager=None) -> dict:
    refresh_n = 0

    if _session_valid(account):
        session = {"cookies": account.get("session_cookies", {}),
                   "token":   account.get("session_token",   "")}
    else:
        session = await browser_auth(account, site)
        if state_manager:
            await state_manager.write(
                "UPDATE accounts SET session_expires_at=?,session_token=? WHERE id=?",
                (session["expires_at"], session["token"], account["id"]))

    async with AsyncSession(
        impersonate="chrome124",
        proxies={"https": account["proxy"]["endpoint"]},
    ) as s:
        for name, value in session["cookies"].items():
            s.cookies.set(name, value)

        while True:
            r = await s.post(f"{site}/api/task/checkin",
                json={"task_id": task["id"]},
                headers={"Authorization": f"Bearer {session['token']}"},
                timeout=15)

            if r.status_code in (401, 403) and any(
                    k in r.text[:300].lower() for k in CHALLENGE_KW):
                refresh_n += 1
                if refresh_n > 2:
                    return {"_tier_escalate": "tier3",
                            "reason": f"session refresh failed ×{refresh_n}"}
                logger.warning("Session expired for %s, re-authing...", account["id"])
                session = await browser_auth(account, site)
                if state_manager:
                    await state_manager.write(
                        "UPDATE accounts SET session_expires_at=?,session_token=? WHERE id=?",
                        (session["expires_at"], session["token"], account["id"]))
                for name, value in session["cookies"].items():
                    s.cookies.set(name, value)
                continue

            return {"status": "ok", "data": r.json(), "tier": "tier2"}
```

```sql
-- accounts 表扩展
ALTER TABLE accounts ADD COLUMN session_expires_at TEXT;   -- UTC ISO-8601
ALTER TABLE accounts ADD COLUMN session_token       TEXT;  -- Bearer token
ALTER TABLE accounts ADD COLUMN session_cookies     TEXT;  -- JSON（cf_clearance 等）
ALTER TABLE accounts ADD COLUMN session_source      TEXT;  -- tier1 | tier2_browser
```

---

### Tier 3：纯 DOM 脚本模式

**适用**：DataDome / PerimeterX / Kasada / F5 / 瑞数等高强度防作弊；或 Tier 2 连续失败的场景。  
**策略**：全程 Playwright，每步模拟人类行为，配合 stealth 补丁、选择器降级链、运行时 CAPTCHA 处理。

#### 工程问题对照表

| 原始问题 | 补全方案 |
|---|---|
| 无头浏览器被识别 | `playwright-stealth` + 手动修补 `navigator.webdriver`、`window.chrome` |
| 选择器改版失效 | 四级降级链：`data-testid` → `aria-label` → `id` → CSS class，逐一尝试 |
| 操作节奏机械 | 每步注入 log-normal 随机延迟（均值 1.2s，σ 0.4s） |
| 运行时遭遇 CAPTCHA | 检测页面 CAPTCHA widget → 调用 Solver API → 注入结果后继续 |
| 失败无法复盘 | `try/except` 末尾截图存档 + 记录 URL + page title |
| 多账号内存爆炸 | 每账号独立 `BrowserContext`，完成即 `ctx.close()`，不共享 Browser |
| 并发过高 | `asyncio.Semaphore(4)` 控制同时执行的 Tier 3 任务数 |

```python
# plugins/tier3_dom.py  |  pip install playwright playwright-stealth
import asyncio, random, math, logging, pathlib
from datetime import datetime, timezone
from playwright.async_api import async_playwright, Page
from playwright_stealth import stealth_async
from core.behavior import human_move_and_click
from core.browser_factory import launch_browser

logger       = logging.getLogger(__name__)
SCREENSHOT_DIR = pathlib.Path("logs/screenshots")
SCREENSHOT_DIR.mkdir(parents=True, exist_ok=True)

TIER3_SEMAPHORE = asyncio.Semaphore(4)   # 最多 4 个并发 Tier 3 任务

def _lognormal_delay(mean_s: float = 1.2, sigma: float = 0.4) -> float:
    """人类操作间隔符合 log-normal 分布（见补丁 v1.8 §5.1）。"""
    mu = math.log(mean_s) - sigma ** 2 / 2
    return min(max(random.lognormvariate(mu, sigma), 0.3), 5.0)

# ── 选择器四级降级链 ──
async def _click_with_fallback(page: Page, selectors: list[str],
                                profile_id: str) -> None:
    """依次尝试选择器列表，第一个成功的即用于 human_move_and_click。"""
    for sel in selectors:
        try:
            el = await page.wait_for_selector(sel, timeout=5_000, state="visible")
            if el:
                await human_move_and_click(page, sel, profile_id)
                return
        except Exception:
            continue
    raise RuntimeError(f"All selectors failed: {selectors}")

# ── 运行时 CAPTCHA 检测与处理 ──
async def _handle_runtime_captcha(page: Page, site: str) -> bool:
    """检查当前页面是否出现 CAPTCHA widget，若是则调用 solver。返回是否处理了 CAPTCHA。"""
    gt = await page.evaluate("window.captcha_gt || null")
    if not gt:
        return False
    from plugins.tier2_semi_protocol import _solve_captcha_if_present
    await _solve_captcha_if_present(page, site)
    return True

async def run_tier3(task: dict, account: dict, site: str) -> dict:
    async with TIER3_SEMAPHORE:
        async with async_playwright() as p:
            ctx  = await launch_browser(p, account)   # 含 browserforge 指纹 + 代理
            page = await ctx.new_page()

            # ① Stealth 补丁：消除 Playwright 特征（navigator.webdriver、chrome runtime 等）
            await stealth_async(page)

            ts_prefix = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
            try:
                # ② 登录（四级选择器降级链 + 人类延迟）
                await page.goto(f"{site}/login", wait_until="networkidle", timeout=30_000)
                await asyncio.sleep(_lognormal_delay())

                await _click_with_fallback(page, [
                    '[data-testid="email-input"]', '[aria-label="邮箱"]',
                    '#email', '[name="email"]',
                ], account["behavior_profile_id"])
                await page.fill('[name="email"]', account["email"])
                await asyncio.sleep(_lognormal_delay(0.5, 0.2))

                await _click_with_fallback(page, [
                    '[data-testid="password-input"]', '[aria-label="密码"]',
                    '#password', '[name="password"]',
                ], account["behavior_profile_id"])
                await page.fill('[name="password"]', account["password"])
                await asyncio.sleep(_lognormal_delay())

                # CAPTCHA 出现时处理
                await _handle_runtime_captcha(page, site)

                await _click_with_fallback(page, [
                    '[data-testid="submit-btn"]', '[aria-label="登录"]',
                    '#login-btn', '[type="submit"]',
                ], account["behavior_profile_id"])
                await page.wait_for_url(f"{site}/dashboard", timeout=45_000)
                await asyncio.sleep(_lognormal_delay(1.5, 0.5))

                # ③ 业务步骤（从 dom_ops.jsonl 提取的核心操作序列）
                await _handle_runtime_captcha(page, site)   # 业务页也可能有 CAPTCHA
                await _click_with_fallback(
                    page,
                    task.get("selectors", [task.get("selector", "")]),
                    account["behavior_profile_id"],
                )
                await page.wait_for_selector(
                    task.get("confirm_selector", ".success"), timeout=15_000)

                result = {"status": "ok", "tier": "tier3",
                          "url": page.url, "title": await page.title()}

            except Exception as e:
                # ④ 失败截图存档
                shot = SCREENSHOT_DIR / f"{account['id']}_{ts_prefix}_fail.png"
                await page.screenshot(path=str(shot), full_page=True)
                logger.error("Tier3 failed for %s: %s | url=%s | screenshot=%s",
                             account["id"], e, page.url, shot)
                result = {"status": "error", "tier": "tier3",
                          "error": str(e), "screenshot": str(shot)}

            finally:
                await ctx.close()   # Context 完成即关，不关闭 Browser 进程本身

        return result
```

> `human_move_and_click` 多策略鼠标混合实现见补丁文档 v1.8 §5.2。  
> `launch_browser` 含 browserforge 指纹注入 + 代理绑定，见主框架设计文档 v1.7 §4.2。

#### 并发建议

| 机器配置 | 推荐 Tier 3 并发数 | TIER3_SEMAPHORE 值 |
|---|---|---|
| 4 核 8 GB | 2~3 | `Semaphore(2)` |
| 8 核 16 GB | 4~6 | `Semaphore(4)` |
| 16 核 32 GB | 8~12 | `Semaphore(8)` |

---

### 3.4 运行时自动降级调度器

调度器负责接收各 Tier 返回的 `_tier_escalate` 信号，自动升级并重试：

```python
# core/executor.py
import logging
from plugins.tier1_protocol    import run_tier1
from plugins.tier2_semi_protocol import run_tier2
from plugins.tier3_dom         import run_tier3

logger = logging.getLogger(__name__)

TIER_RUNNERS = {"tier1": run_tier1, "tier2": run_tier2, "tier3": run_tier3}

async def execute_with_fallback(task: dict, account: dict, site: str,
                                 start_tier: str = "tier1",
                                 state_manager=None) -> dict:
    """
    从 start_tier 开始执行，若返回 _tier_escalate 则自动升级并重试。
    Tier 3 是最终兜底，失败直接返回错误（记录 task_runs.status=failed）。
    """
    tier_order = ["tier1", "tier2", "tier3"]
    current    = tier_order.index(start_tier)

    while current < len(tier_order):
        tier   = tier_order[current]
        runner = TIER_RUNNERS[tier]
        logger.info("Executing %s/%s via %s", account["id"], task["id"], tier)

        result = await runner(task, account, site, **(
            {"state_manager": state_manager} if tier == "tier2" else {}))

        if "_tier_escalate" in result:
            next_tier = result["_tier_escalate"]
            logger.warning("Escalating %s → %s: %s",
                           tier, next_tier, result.get("reason"))
            # 更新 site_recon.tier_verdict（实测发现需要更高 Tier）
            if state_manager:
                await state_manager.write(
                    "UPDATE site_recon SET tier_verdict=? WHERE domain=?",
                    (next_tier, site.split("//")[-1].split("/")[0]))
            current = tier_order.index(next_tier)
            continue

        return result

    return {"status": "error", "reason": "all tiers exhausted"}
```

---

## Phase 4：AI 自动生成不同 Tier 的脚本

**输入**：`session.har` + `dom_ops.jsonl` + 侦察结果（`tier_verdict`）  
**输出**：对应 Tier 的可执行 Python 脚本

### 4.1 Prompt 模板（按 Tier 选择）

````markdown
# [Tier 1] 纯协议脚本生成 Prompt

你是一位精通 curl_cffi 和 HTTP 协议的 Python 工程师。

## 输入数据
以下是从浏览器录制的 HAR 文件中提取的请求序列（JSON 格式）：
```json
{HAR_REQUESTS_JSON}
```

## 任务要求
1. 使用 `curl_cffi.requests.AsyncSession(impersonate="chrome124")` 实现以下接口序列：
   {REQUEST_SEQUENCE_SUMMARY}
2. 动态提取认证 token（从登录响应的 JSON body 或 Set-Cookie 中）
3. 正确传递 Referer、Origin、Sec-Fetch-* 等上下文 Header
4. 参数中识别动态值（如 CSRF token、时间戳），用变量替代
5. 返回最终业务结果，用 try/except 包裹每个请求

## 输出格式
完整的 Python async 函数，函数签名：
`async def run_task(account: dict, task: dict) -> dict`
````

````markdown
# [Tier 3] 纯 DOM 脚本生成 Prompt

你是一位精通 Playwright 和 Page Object Model 的 Python 工程师。

## 输入数据
以下是录制的 DOM 操作序列（JSONL 格式，每行一个操作）：
```jsonl
{DOM_OPS_JSONL}
```

## 任务要求
1. 使用 Playwright async API 实现以下操作序列
2. 每个点击操作替换为调用 `human_move_and_click(page, selector, profile_id)` 而非 `page.click()`
3. 选择器优先级：data-testid > aria-label > id > css class（取最稳定的一个）
4. 每步操作后添加 `page.wait_for_selector()` 或 `page.wait_for_load_state()` 确认
5. 捕获最终结果（截图 + 关键 DOM 文本）

## 输出格式
完整的 Python async 函数，函数签名：
`async def run_task(account: dict, task: dict) -> dict`
````

---

## 工具链汇总与依赖

```diff
# requirements.txt 新增
+ curl_cffi>=0.7.0        # 纯协议 TLS/JA3/HTTP2 指纹伪装（Tier 1 / Tier 2）
  playwright>=1.40.0      # DOM 录制 + Tier 3 执行（主框架已有）

# 侦察工具（独立脚本，无需集成到主框架）
+ wappalyzer              # 可选：浏览器插件辅助识别（https://www.wappalyzer.com）
```

| 工具 | 作用 | Tier |
|---|---|---|
| `curl_cffi` | TLS/JA3/HTTP2 指纹伪装的纯协议 HTTP 客户端 | Tier 1 / 2 |
| `Playwright recordHar` | 人工操作时同步录制 HAR 网络流量 | 录制阶段 |
| `page.add_init_script` | 注入 DOM 操作监听，捕获用户事件流 | 录制阶段 |
| `curl_cffi Session.cookies` | 将浏览器 auth 导出的 cookie 注入协议 session | Tier 2 |
| `human_move_and_click` | 多策略鼠标行为混合（见补丁 v1.8） | Tier 3 |
| LLM（GPT-4o / Claude 3.5） | 消费 HAR + DOM ops，AI 生成对应 Tier 脚本 | 脚本生成 |

---

## 与主框架集成点

| 本文档概念 | 主框架对应位置 |
|---|---|
| `site_recon` 表 | 新增（不在 v1.7 主框架中） |
| `tier_verdict` 字段 | 新增到 `site_recon` 表；`task_runs` 可记录本次用了哪个 Tier |
| Tier 1 / `curl_cffi` | 替代主框架中的纯 Web2 Playwright 路径（轻量任务） |
| Tier 2 / 浏览器 auth | 与主框架 `browser_factory.py` + `StateManager.session_expires_at` 协同 |
| Tier 3 / 纯 DOM | 主框架现有 Playwright 执行路径（v1.7 完整覆盖） |

---

## 参考来源

| 编号 | 来源 | 地址 |
|---|---|---|
| [1] | Dima Kynal, "Anti-Bot Protection and How Detect It", Medium, Aug 2024 | https://medium.com/@dimakynal/anti-bot-protection-and-how-detect-it-4027a9690fb5 |
| [2] | WebAutomation.io, "The Ultimate Guide to Web Scraping Antibot Systems (2025)", Oct 2025 | https://webautomation.io/blog/ultimate-guide-to-web-scraping-antibot-and-blocking-systems-and-how-to-bypass-them/ |
| [3] | Scrapfly, "How to Bypass Akamai when Web Scraping in 2026", Sep 2025 | https://scrapfly.io/blog/posts/how-to-bypass-akamai-anti-scraping |
| [4] | curl_cffi Documentation, "Impersonate Guide" | https://curl-cffi.readthedocs.io/ |
| [5] | arxiv:2602.09606, "When Handshakes Tell the Truth: Detecting Web Bad Bots via TLS Fingerprinting", Feb 2026 | https://arxiv.org/html/2602.09606v1 |
| [6] | Playwright docs, "Mock APIs / recordHar" | https://playwright.dev/docs/mock |
| [7] | Medium/@dimakynal, "Exploring Python Libraries: tls_client vs curl_cffi", 2024 | https://medium.com/@dimakynal/exploring-python-libraries-tls-client-vs-curl-cffi-for-web-requests-129b7888e1f6 |

---

*文档版本：v1.0 | 创建日期：2026-02-19 | 对应主框架：框架设计文档_v1.md v1.7 + 框架补丁_v1.8*
