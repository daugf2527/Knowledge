# 薅羊毛自动化框架 — 完整设计文档 v1.6

> 文档状态：设计阶段（2026-02-19）  
> 目标规模：30–100 账号，Web2 + Web3 双场景  
> 核心原则：方案想清楚再动手，做可扩展框架而非一次性脚本

---

## 0. 为什么需要框架而不是脚本

"薅羊毛"的最大失败模式不是被检测，而是**规模扩张后维护崩溃**：
- 每个平台一个脚本，平台改版后全部作废
- 账号多了不知道哪个跑过了、哪个封了、哪个任务差一步
- 失败了不知道是被检测、改版、还是网络问题
- 新增平台要从头重写，没有任何复用

框架的价值：新增平台只写一个"任务插件"，调度/账号/日志/浏览器/反检测全部复用。

---

## 1. 系统边界定义

### 1.1 框架做什么（In Scope）

| 能力 | 描述 |
|---|---|
| 账号生命周期管理 | 配置、状态机（活跃/冷却/封禁）、属性绑定（指纹/代理/钱包） |
| 任务调度 | 多账号并发、随机延迟、批次错峰、失败重试、优先级 |
| 浏览器执行 | 带反检测的浏览器、指纹注入、代理、独立环境隔离 |
| Web2任务执行 | 导航/点击/填表/滚动/输入等通用操作 |
| Web3任务执行 | 钱包连接、签名确认、链上交互、MetaMask弹窗 |
| 状态持久化 | 任务完成记录、账号状态、执行日志、错误追踪 |
| 结果报告 | 每日汇总、成功率、收益记录、异常告警 |
| 插件机制 | 新平台只需实现插件接口，不改核心框架 |

### 1.2 框架不做什么（Out of Scope）

| 不做 | 原因 |
|---|---|
| 账号注册/创建 | 注册风控极强，框架假设账号已存在 |
| 私钥托管/资金管理 | 安全边界，框架只引用配置，不持有资产 |
| 验证码全自动破解 | 先接第三方打码，手动兜底 |
| DeFi实时套利 | 延迟要求极高，不在范围 |
| 链上女巫资金混淆 | 手动规划资金路径，框架只执行已规划步骤 |

### 1.3 成功标准（SLO/SLI）

> 可控 SLI（框架可观测并直接负责）：

| 指标 | 目标 | 说明 |
|---|---|---|
| **任务成功率（可控失败）** | ≥ 80% | 排除 `redesign` / `platform_ban` 类失败；仅统计框架可控的 `network` / `rate_limited` 错误 |
| **插件开发交付时间** | ≤ 2 天 | 从需求到端到端跑通（含调试）|
| **改版修复 MTTR** | ≤ 4 小时 | 从告警触发到插件修复上线 |
| **无变更 Flake Rate** | ≤ 5% | 同一周内无代码变更，相同任务的重试成功率反映框架稳定性 |
| **告警误报率** | ≤ 10% | Telegram 告警中属于"假阳性"（实为平台正常维护）的比例 |
| **暂停任务平均恢复时长** | ≤ 2 天 | 人工恢复；超 72h 未恢复则自动再次告警 |

> 不可控指标（平台侧决策，框架无法保证为 0）：

- 封号数量、批量清查事件 — 框架只能记录、告警，无法承诺发生率

#### SLI SQL 参考实现（统计口径唯一真源）

> 避免每次查报表时口径漂移（"这次要不要算 skipped？"）

```sql
-- 1. 任务成功率（可控失败分母）
--    分母：排除 redesign / account_issue / platform_ban
--    分子：status = 'success'
SELECT
    ROUND(
        100.0 * SUM(CASE WHEN status='success' THEN 1 ELSE 0 END)
        / NULLIF(COUNT(*), 0),
        1
    ) AS controllable_success_rate_pct
FROM task_runs
WHERE finished_date_utc = ?                                   -- 指定日期（UTC）
  AND failure_type NOT IN ('redesign','account_issue','platform_ban')
  AND status != 'skipped';                                    -- skipped 不计入分母

-- 2. 无变更 Flake Rate（某任务在无代码变更窗口内的不稳定率）
SELECT
    task_id,
    ROUND(
        100.0 * SUM(CASE WHEN status='failed'
                         AND failure_type IN ('network','rate_limited','proxy_fallback')
                    THEN 1 ELSE 0 END)
        / NULLIF(COUNT(*), 0),
        1
    ) AS flake_rate_pct
FROM task_runs
WHERE finished_date_utc BETWEEN ? AND ?                       -- 统计窗口（UTC 日期）
GROUP BY task_id;

-- 3. 按拦截策略统计成功率（排查 block_policy 是否影响成功率）
SELECT
    rp.policy_id,
    COUNT(*)                                             AS total,
    SUM(CASE WHEN tr.status='success' THEN 1 ELSE 0 END) AS success
FROM task_runs tr
LEFT JOIN request_policies rp ON tr.block_policy_id = rp.policy_id
WHERE tr.finished_date_utc = ?
GROUP BY rp.policy_id;
```

> `failure_type` 枚举（唯一真源，与 `task_runs` schema 注释一致）：
> - **可控**（纳入 SLI 分母）：`network` | `rate_limited` | `proxy_fallback`
> - **不可控**（排除 SLI 分母）：`redesign` | `account_issue` | `platform_ban`
> - `skipped`：不是 failure_type，是 status；不计入成功率分母

---

## 2. 设计哲学与核心原则

### 原则一：隔离是最高优先级

每个账号是完全独立的"宇宙"：独立指纹、独立IP、独立Cookie、独立钱包、独立浏览器进程。任何一个维度泄露 = 关联封禁。

```
账号A：指纹A + IP-A + Cookie-A + 钱包-A + 进程-A
账号B：指纹B + IP-B + Cookie-B + 钱包-B + 进程-B
              ↑
        两个宇宙无任何交叉
```

### 原则二：符合统计分布的随机才有效

不是"有延迟"让你安全，是"符合人类统计分布的随机延迟"让你安全。现代风控用机器学习分析行为熵值，uniform随机分布、Gaussian 正态分布和固定延迟一样容易被识别（正态分布的对称性同样会被 ML 模型标记）。

```python
# ❌ 固定延迟
time.sleep(2)

# ❌ 简单随机（uniform分布仍可被ML识别）
time.sleep(random.uniform(1, 3))

# ❌ 正态分布（对称分布，ML 可通过偏度/峰度检测识别为机器）
# random.gauss(mean, std)

# ✅ 对数正态分布（长尾效应：短操作密集+偶尔发呆，符合人类行为动力学）
import math
def human_delay(mean=2.0, sigma=0.5, min_val=0.3):
    mu = math.log(mean) - (sigma ** 2) / 2   # 对数空间均值
    delay = random.lognormvariate(mu, sigma)
    if random.random() < 0.01:               # 1% 概率模拟"发呆"长停顿
        delay += random.uniform(5, 20)
    return max(min_val, delay)
```

### 原则三：失败必须分类，不同失败对应不同处理

| 失败类型 | 判断信号 | 处理策略 |
|---|---|---|
| 平台改版 | 选择器失效、元素消失 | 暂停任务 + 告警 + 等人工修复 |
| 网络/超时 | 加载超时、TCP连接失败 | 自动重试（最多3次，指数退避） |
| 被风控拦截 | 出现验证码、403、风控跳转 | 账号冷却24h + 记录 + 不重试 |
| 任务已完成 | 平台显示"已领取/已完成" | 标记成功，正常退出 |
| 账号异常 | 登录失败、账号被锁 | 标记suspended + 告警 + 跳过 |

### 原则四：插件化保证可扩张性

核心框架对任务只认一个接口，平台定制全部在插件里：

```python
class TaskPlugin:
    async def run(self, account: Account, page: Page) -> TaskResult:
        """平台相关逻辑全在这里"""
        raise NotImplementedError

    def should_run_today(self, account: Account) -> bool:
        """判断今天是否需要运行（避免重复执行）"""
        raise NotImplementedError
```

### 原则五：可观测性优先于速度

宁可跑慢一点，日志必须完整。没有日志的失败等于没有发生，无法定位问题，无法改进。每次任务执行都记录：开始时间、结束时间、失败原因、操作截图（失败时）。

### 原则六：最小化登录次数

登录操作是风险最高的行为（账号密码明文传输、新设备检测、验证码触发率高）。框架通过 Cookie 持久化最大化减少登录次数：Cookie有效→直接用，过期→最小化重新登录，登录后立即保存Cookie。

---

## 3. 整体架构

### 3.1 五层架构图

```
┌──────────────────────────────────────────────────┐
│             Layer 5: 监控与报告层                  │
│  日志聚合 / 每日报表 / 成功率看板 / TG Bot告警      │
└──────────────────────┬───────────────────────────┘
                       │
┌──────────────────────▼───────────────────────────┐
│             Layer 4: 状态持久化层                  │
│   SQLite：账号状态/任务记录/代理池/执行日志          │
└──────────┬───────────────────────┬───────────────┘
           │                       │
┌──────────▼───────────────────────▼───────────────┐
│             Layer 3: 调度引擎层                    │
│  任务队列/并发控制(max8)/批次错峰/重试/时间随机化   │
└──────┬──────────────────────────────────┬─────────┘
       │                                  │
┌──────▼───────────────┐   ┌──────────────▼────────┐
│  Layer 2A: Web2引擎   │   │  Layer 2B: Web3引擎    │
│  Zendriver +          │   │  Playwright+Synpress   │
│  browserforge指纹层   │   │  + MetaMask扩展        │
│  ghost-cursor行为     │   │  签名延迟模拟器         │
└──────────┬────────────┘   └──────────┬────────────┘
           │                           │
┌──────────▼───────────────────────────▼────────────┐
│             Layer 1: 账号与配置管理层               │
│  账号池/代理池/指纹库/钱包配置/任务定义/全局参数    │
└────────────────────────────────────────────────────┘
```

### 3.2 每日数据流

```
Cron 触发（09:00 UTC+8 + 随机偏移）
    ↓
调度引擎：加载 active 账号 → 过滤今日已完成 → 随机打乱顺序
    ↓
分批执行（每批 ≤ 8，批间等待 30~60 分钟）
    每账号（批内随机错开 30~300 秒启动）：
        加载配置 → 启动独立浏览器 → 串行跑任务插件 → 写DB → 关浏览器
    ↓
全部完成 → 生成每日报表 → 推送 Telegram
```

### 3.3 项目目录结构

```
auto_farm/
├── core/                    # 核心框架（不涉及具体平台）
│   ├── account.py           # 账号数据模型
│   ├── scheduler.py         # 调度引擎
│   ├── browser_factory.py   # 浏览器工厂（Web2/Web3 分支）
│   ├── state_manager.py     # SQLite 封装
│   ├── reporter.py          # 日报生成
│   ├── behavior.py          # 行为模拟工具库
│   └── base_task.py         # 插件基类 + TaskResult 模型
│
├── plugins/                 # 任务插件（按平台一个文件）
│   ├── web2/
│   │   ├── zealy_checkin.py
│   │   ├── twitter_retweet.py
│   │   └── discord_daily.py
│   └── web3/
│       ├── galxe_quest.py
│       ├── layer3_task.py
│       └── defi_swap.py
│
├── config/
│   ├── accounts/            # 每账号一个 YAML
│   ├── tasks.yaml           # 任务调度配置
│   └── global.yaml          # 全局参数
│
├── data/
│   ├── farm.db              # SQLite 主库
│   ├── cookies/             # Cookie 持久化（账号+平台）
│   ├── metamask_profiles/   # MetaMask 独立配置目录
│   └── logs/                # 执行日志（按日期）
│
├── secrets/                 # ❌ .gitignore 排除，不进版本控制
│   ├── proxies.json
│   └── wallets.enc.json     # 加密存储私钥（Fernet对称加密，密钥由 WALLET_ENC_KEY 环境变量提供）
│
└── main.py
```

---

## 4. 各层详细设计

### 4.1 Layer 1：账号与配置管理层

#### 账号 YAML 完整示例（acc_001.yaml）

```yaml
id: acc_001
display_name: "Account Alpha"

proxy:
  type: residential              # 禁止 datacenter！
  provider: oxylabs
  endpoint: "pr.oxylabs.io:7777"
  username: "user-acc001"
  password: "${PROXY_PASS_001}"  # 环境变量注入，不明文
  country: US
  city: LosAngeles
  sticky_session: true           # 粘性会话，不轮换IP
  # IP 跌落降级（住宅IP随时可能失效，勿假设可稳定2-4周）
  fallback_asn: "AS7922"         # 跌落时，只在同ISP/ASN内换IP（Comcast示例）
  fallback_strategy: same_asn    # same_asn | same_city | abort（禁止全局随机换IP）
  # 跌落检测口径（必须精确定义，防止把任务失败误判为代理跌落）
  fallback_trigger_errors: 2     # 连续 N 次"代理层"错误触发切换（非任务逻辑错误）
  # 判定为"代理跌落"的异常类型（排他列表）：
  #   ✅ network_timeout: TCP 连接超时（asyncio.TimeoutError 在建连阶段）
  #   ✅ tcp_fail: 连接被拒绝（ConnectionRefusedError, ConnectionResetError）
  #   ✅ proxy_auth_fail: HTTP 407 代理认证失败
  #   ❌ platform_5xx: 平台服务端错误 → 归类为 network_failed，不触发切换
  #   ❌ cloudflare_challenge: 风控拦截 → 归类为 rate_limited，不触发切换
  #   ❌ dns_fail: DNS 解析失败 → 归类为 network_failed（代理 DNS 不可靠，不触发切换）
  # 统计窗口：同一账号，当前任务执行周期内（不跨任务）；任务结束后计数清零
  # 状态机影响：IP 跌落触发切换后，当前任务标记 status=failed / failure_type=proxy_fallback
  #   然后调度器安排重试（走正常指数退避流程），不跳过冷却

fingerprint:
  os: windows
  os_version: "10"
  browser: chrome
  browser_version: "120"
  screen: "1920x1080"
  timezone: "America/Los_Angeles"
  language: "en-US,en;q=0.9"
  hardware_concurrency: 4
  device_memory: 8
  # canvas/webgl/audio 由 browserforge 自动匹配

web2_accounts:
  twitter:
    username: "alice_web2"
    password: "${ACC001_TWITTER_PASS}"
    session_cookie_ref: "data/cookies/acc001_twitter.json"
  zealy:
    session_cookie_ref: "data/cookies/acc001_zealy.json"
  discord:
    token_ref: "${ACC001_DISCORD_TOKEN}"

wallets:
  evm:
    address: "0x742d35Cc6634C0532925a3b8D4C0523b8F8e74"
    metamask_profile_dir: "data/metamask_profiles/acc001/"
    keystore_ref: "${ACC001_WALLET_KEYSTORE}"  # 运行时注入
    networks: [ethereum, base, arbitrum, optimism]
  solana:
    address: "7xKXtg2CW87d97TXJSDpbD5jBkheTqA83TZRuJosgAsU"
    keypair_ref: "${ACC001_SOL_KEYPAIR}"

status: active           # active | cooldown | suspended | banned
cooldown_until: null
created_at: "2025-10-01"

task_subscriptions:
  - galxe_daily_checkin
  - zealy_quest_complete
  - twitter_project_retweet
```

#### 关键配置约束

| 约束 | 规则 |
|---|---|
| 指纹-代理地区一致性 | timezone/language 必须与 proxy.city 地区匹配 |
| 代理类型强制 | type 只允许 residential 或 mobile，datacenter 直接拒绝启动 |
| 私钥存储 | 所有凭据只允许引用环境变量或 secrets/ 加密文件，禁止明文。加密方案：`cryptography` 库 Fernet（AES-128-CBC + HMAC-SHA256），密钥 `WALLET_ENC_KEY=Fernet.generate_key()` 写入 `.env` |
| 指纹固定性 | 同账号指纹一旦设定不轮换，轮换 = 产生新身份 = 触发新设备检测 |

#### 全局参数（global.yaml）

```yaml
scheduler:
  max_concurrent_accounts: 8
  inter_account_delay_seconds: [30, 300]   # 批内账号间随机延迟
  inter_batch_delay_seconds: [1800, 3600]  # 批间等待 30-60 分钟

behavior:
  # behavior_profile_id：行为参数版本号，写入每条 task_run 记录
  # 修改任何参数时必须递增版本号，否则成功率变化无法归因（是平台变了？还是参数变了？）
  behavior_profile_id: "v1.0"
  # ab_group: "control"   # 未来 AB 实验时启用；"control" 使用当前参数，"experiment" 使用下方参数
  page_load_wait_ms: [2000, 5000]
  element_click_delay_ms: [500, 2000]
  typing_delay_per_char_ms: [80, 200]
  wallet_sign_wait_ms: [3000, 8000]        # 签名等待（关键！）
  post_action_wait_ms: [1000, 3000]
  scroll_pause_ms: [500, 1500]
  # 对数正态分布参数（human_delay 使用）
  lognormal_sigma: 0.5                     # 越大长尾越明显；调整此值必须同时更新 behavior_profile_id

captcha:
  service: capsolver
  api_key: "${CAPSOLVER_KEY}"
  timeout_seconds: 120
  fallback: alert_and_wait

alerts:
  telegram:
    enabled: true
    bot_token: "${TG_BOT_TOKEN}"
    chat_id: "${TG_CHAT_ID}"
  triggers:
    - event: account_banned
    - event: task_consecutive_failures
      threshold: 3
    - event: daily_batch_complete
```

---

### 4.2 Layer 3：调度引擎层

#### 调度主流程

```
Cron 09:00 UTC+8（+ 随机 0~30 分钟偏移）
    ↓
1. 加载所有 status=active 账号
2. 对每个账号，查询今日 task_subscriptions 中 schedule 匹配的任务
3. 用 DB 过滤掉 "今日 + success" 的记录
4. 随机打乱账号列表（每天顺序不同）
5. 分批执行（每批 ≤ max_concurrent_accounts=8）：
   a. 批内：各账号随机错开 30~300 秒启动
   b. 每账号：加载配置 → 启动浏览器 → 串行跑任务 → 关浏览器
   c. 等待该批全部完成（或超时）
   d. 批间：等待 1800~3600 秒
6. 全部批次完成 → 触发日报
```

#### 4 个关键调度决策

**决策 A：同账号串行，禁止并发多任务**
- 共享浏览器实例，并发会状态混乱
- 真实用户不会同时在两个标签页操作不同平台
- 并发行为熵值偏离正常人类分布

**决策 B：失败用指数退避，不立即重试**
```
第1次失败 → 等 60 秒 → 第1次重试
第2次失败 → 等 300 秒 → 第2次重试
第3次失败 → 等 900 秒 → 第3次重试
第3次仍失败 → 标记 needs_human，不再重试
```
被风控后立即重试 = 加深封禁；平台改版后重试无意义。

**决策 C：同平台跨账号强制错峰**
```
❌ 错误：09:00 所有 100 账号同时访问 Galxe（流量峰值极明显）

✅ 正确：全天分批，批间隔 30-60 分钟
  批1（08:35）→ acc01, acc07, acc14, acc22, acc31, acc40, acc55, acc68
  批2（10:12）→ acc02, acc08, acc15, acc23, acc32, acc41, acc56, acc69
  批3（12:47）→ acc03, acc09, acc16, acc24, acc33, acc42, acc57, acc70
  ...
```

**决策 D：账号顺序每天随机打乱**
固定顺序（每天都是 acc_001 先跑）也是可被识别的模式，每次执行前 `random.shuffle(accounts)`。

#### Time Model（时区与"今日"窗口的唯一规范定义）

> ⚠️ **P0 设计约束**：账号指纹使用 `America/Los_Angeles` 时区，调度基准写 `UTC+8`，报表也有独立时区——三处不统一必然导致重复跑/漏跑。以下是系统唯一时区规范，所有模块必须遵守。

| 上下文 | 使用的时区 | 说明 |
|---|---|---|
| 调度器基准 / `should_run_today` | **UTC** | 内部调度全程使用 UTC，不依赖运行机器本地时区 |
| DB 中所有时间戳 | **UTC ISO-8601** | `task_runs.finished_at` 等字段均存 UTC ISO-8601 字符串 |
| 日报 `date` 字段 | **UTC 日期** | `daily_summary.date = utc_today()` |
| 账号指纹 `timezone` | 账号归属地时区 | **仅用于浏览器 JS 行为伪装**，与调度逻辑完全无关 |
| 对外展示（Telegram 报告） | UTC+8 | 展示层做 +8 转换，写入 DB 时仍用 UTC |

```python
from datetime import datetime, date, timezone

def utc_today() -> date:
    # ✅ 显式 timezone.utc，与系统时区无关
    return datetime.now(timezone.utc).date()

def utc_now_iso() -> str:
    return datetime.now(timezone.utc).isoformat()  # "2026-02-19T10:32:00+00:00"

def should_run_today(account_id: str, task_id: str, db: StateManager) -> bool:
    today_str = utc_today().isoformat()      # e.g. "2026-02-19"
    # ✅ 直接 WHERE finished_date_utc=? 精确匹配（TEXT = TEXT），避免 SQLite
    #    date("2026-02-19T10:32:00+00:00") 返回 NULL 或解析错误的问题
    rows = db.read(
        "SELECT 1 FROM task_runs WHERE account_id=? AND task_id=? "
        "AND finished_date_utc=? AND status='success'",
        (account_id, task_id, today_str)
    )
    return len(rows) == 0

# 写入 task_run 时同时计算 finished_date_utc：
# finished_at     = utc_now_iso()            # "2026-02-19T10:32:00+00:00"
# finished_date_utc = utc_today().isoformat() # "2026-02-19"
# 两列均在同一事务内写入，保证一致性
```

`TZ=UTC` 仍建议在部署时设置（`Dockerfile`/systemd `Environment=TZ=UTC`）作为防御层，但程序逻辑**不依赖**它——`datetime.now(timezone.utc)` 无论系统时区如何都正确。

---

### 4.3 Layer 2A：Web2 执行引擎

#### 浏览器栈选型（2025/2026 实测基准）

| 工具 | Cloudflare | Akamai | Datadome | 维护状态 | 推荐 |
|---|---|---|---|---|---|
| **Zendriver** | ✅ | ✅ | ❌ | 活跃 | 主力 |
| Camoufox | 高指纹质量 | - | - | ⚠️ 2026维护缺口 | 待评估 |
| Playwright 原生 | ❌ | ❌ | ❌ | 活跃 | 不可用 |
| undetected-chromedriver | ❌ | ❌ | ❌ | 退场 | 不可用 |

**Datadome 问题**：目前无开源方案稳定穿透。遇到 Datadome 保护的平台，评估是否值得用商业方案（Bright Data Scraping Browser），或直接跳过该平台。

**推荐组合**：
- Zendriver（绕过能力）
- browserforge（Apify fingerprint-suite 的 Python 移植版，开源，统计学一致指纹）
- ghost-cursor（贝塞尔曲线鼠标移动）
- CapSolver（验证码处理）

> ⚠️ **Canvas/WebGL 硬件指纹局限性**：browserforge 只能设置 navigator、屏幕、语言等 JS 层特征。底层 Canvas/WebGL 渲染结果取决于真实 GPU 驱动——在 Linux 服务器上运行的 Chrome 画出的 Canvas 哈希与声称的 "Windows 10 + NVIDIA GTX" 指纹不匹配，形成"缝合怪"被 ML 模型识别。**对策（选其一）**：① 在 Windows 物理机上运行（本项目当前部署环境满足）；② 通过 Zendriver CDP 注入 `HTMLCanvasElement.prototype.toDataURL` Hook；③ 升级为商业防检测内核（AdsPower Local API）。

#### 请求拦截（Web2 流量成本控制）

住宅代理按流量计费（$2-5/GB），现代平台首页媒体资源可达 5-10MB/次。

> ⚠️ **P0 架构约束**：拦截策略是 **task-dependent**（部分任务需要图片/字体才能正确验证 UI 状态），**禁止**放到 `browser_factory` 全局执行。正确抽象：全局默认策略 + 任务级覆写 + run 记录落库。

```python
# core/request_policy.py
# block_types 的值必须与 CDP/Playwright 统一语义的 resourceType 枚举一致：
# media | font | image | stylesheet | script | xhr | fetch | document | other
# 注意：不是 URL 扩展名（*.mp4 是 URL pattern，与 resourceType 是两套不同语义）
from dataclasses import dataclass, field
from typing import List
import json

RESOURCE_TYPES = {"media", "font", "image", "stylesheet", "script", "xhr", "fetch", "document", "other"}

@dataclass
class RequestBlockPolicy:
    block_types: List[str] = field(default_factory=lambda: ["media", "font"])
    # image 默认不拦截（部分任务依赖图片验证 UI 状态）

DEFAULT_POLICY = RequestBlockPolicy()

# base_task.py — Web2 引擎（Zendriver + CDP）
class BaseTask:
    request_block_policy: RequestBlockPolicy = DEFAULT_POLICY

    async def _apply_request_interception(self, page, run_id: str) -> None:
        blocked = self.request_block_policy.block_types
        await self._db.write(
            "UPDATE task_runs SET block_policy=? WHERE id=?",
            (json.dumps(blocked), run_id)     # JSON 序列化，与 schema 定义一致
        )
        # CDP 的 Network.setBlockedURLs 按 URL glob 工作，不直接支持 resourceType
        # 需将 resourceType 转为对应 URL pattern（不完美，仅覆盖主流情况）
        TYPE_TO_PATTERNS = {
            "media":  ["*.mp4", "*.webm", "*.avi", "*.mp3", "*.ogg"],
            "font":   ["*.woff", "*.woff2", "*.ttf", "*.eot", "*.otf"],
            "image":  ["*.png", "*.jpg", "*.jpeg", "*.gif", "*.webp", "*.svg", "*.ico"],
        }
        url_patterns = [p for t in blocked for p in TYPE_TO_PATTERNS.get(t, [])]
        if url_patterns:
            await page.send("Network.setBlockedURLs", {"urls": url_patterns})
            await page.send("Network.enable")
```

> ⚠️ **Web2/Web3 拦截机制不对称**：Web3（Playwright）使用 `route.request().resourceType()` 精确匹配；Web2（Zendriver/CDP）只能用 URL glob（`Network.setBlockedURLs`），resourceType 语义到 URL pattern 的转换不完备（动态 CDN URL 无扩展名不会被拦截）。两者 `block_types` 字段值**定义语义相同**（均指 resourceType 枚举），但执行层不同——这是 CDP API 局限，文档中不应掩盖。

插件覆写示例：
```python
# plugins/web2/needs_images_task.py
class NeedsImagesTask(BaseTask):
    request_block_policy = RequestBlockPolicy(block_types=["media", "font"])  # 图片放行

# plugins/web2/media_heavy_task.py
class MediaHeavyTask(BaseTask):
    request_block_policy = RequestBlockPolicy(block_types=[])  # 全部放行
```

> **术语说明 — "CDP-free 模式"**：本文档中 Zendriver 的"CDP-free"指框架**不通过标准 CDP 端口暴露调试接口**（即不启动 `--remote-debugging-port`，避免被检测为自动化浏览器）；但框架内部仍可通过 Zendriver 封装的 CDP 通道调用 `Network.*` 等协议指令做功能性配置。**框架不对 Zendriver 底层 CDP 实现作任何强假设**——不同版本的 Zendriver 可能改变此行为，切换引擎时须重新验证。

#### Web2 任务执行流程

```
启动账号 Web2 任务
    ↓
1. 加载账号指纹配置
2. 调用 browserforge 生成与指纹匹配的浏览器参数
3. 启动 Zendriver（Chrome CDP-free 模式）
   ├─ 注入代理（SOCKS5，远程DNS解析）
   ├─ 设置 User-Agent 与 Client Hints（与指纹严格一致）
   └─ 设置时区、语言、屏幕分辨率
4. 加载平台持久化 Cookie
   ├─ Cookie 有效 → 跳过登录，直接进入任务
   └─ Cookie 失效 → 执行登录流程 → 保存新 Cookie
5. 随机滚动页面 1~3 次（human_delay(1.5, 0.5)秒间隔）
6. 执行任务插件步骤（贝塞尔曲线鼠标 + 对数正态分布延迟）
7. 遇到验证码：
   ├─ 调用 CapSolver API（timeout=120s）
   └─ 超时 → 告警 Telegram → 等待人工处理
8. 任务完成 → 保存 Cookie → 写 DB → 关闭浏览器
9. 遇到失败 → 分类（原则三）→ 按类型处理
```

#### 登录行为模拟（最小化登录触发）

登录是最高风险操作，每次登录都要严格模拟人类：

```
1. 访问平台首页（不直接访问 /login URL）
2. 鼠标贝塞尔曲线移动到登录入口按钮
3. 停留 random(0.8, 2.0) 秒
4. 点击进入登录页
5. 停留 random(1.5, 3.0) 秒（模拟用户看页面）
6. 鼠标移动到用户名输入框
7. 逐字符输入，每字符间隔 random.gauss(120, 30) ms
8. 有 15% 概率模拟一次删除重输（增加真实性）
9. Tab 切换到密码框（不鼠标点击，模拟键盘习惯）
10. 同样方式输入密码
11. 停留 random(1.0, 2.5) 秒后点击登录
```

---

### 4.4 Layer 2B：Web3 执行引擎

#### Web3 额外复杂性（相比 Web2 新增）

| 挑战 | 说明 |
|---|---|
| MetaMask 扩展控制 | 必须用真实 MetaMask 扩展，不能 mock window.ethereum |
| 签名/交易弹窗 | 弹窗出现后必须等待 3~8 秒再确认 |
| 链上行为去同质化 | 多账号不能有完全相同的交互序列和金额 |
| 女巫检测 | 链上分析追踪资金来源、交互模式、时间分布 |

#### MetaMask 自动化方案

**选型：Synpress**（Web3 E2E 测试事实标准）
- 基于 Playwright，原生支持 MetaMask 弹窗（连接/签名/交易确认）
- 支持多钱包、多网络、多账户

**账号隔离方案**：每账号独立 Chrome 用户数据目录，MetaMask 扩展数据、私钥、配置完全隔离。

```
data/metamask_profiles/
    acc001/   ← Chrome用户目录，MetaMask已导入acc001钱包
    acc002/   ← Chrome用户目录，MetaMask已导入acc002钱包
    acc003/   ← ...
```

#### Web3 任务执行流程

```
启动账号 Web3 任务
    ↓
1. 加载账号独立 Chrome Profile（含 MetaMask + 已导入私钥）
2. 配置代理IP + 指纹参数
3. 启动有头 Chrome（Playwright + Synpress）
4. 导航到 DApp 页面
5. 模拟真实浏览行为：
   ├─ 随机滚动页面 2~3 次
   └─ 停留 random(3, 8) 秒
6. 点击"连接钱包"按钮
7. MetaMask 连接弹窗（Synpress 处理）：
   ├─ 弹窗出现后等 random(2, 5) 秒（模拟用户查看）
   └─ 点击"连接"
8. 执行业务操作（按插件定义步骤）
9. 签名/交易弹窗（关键节点）：
   ├─ 普通签名：等 random(3, 8) 秒
   ├─ 授权交易：等 random(5, 12) 秒
   └─ 大额转账：等 random(8, 20) 秒
10. 等待链上确认（轮询，timeout=120s）
11. 验证任务完成（UI状态或链上事件）
12. 写 DB → 关浏览器
```

#### Web3 链上反女巫策略（账号运营层面）

> 这部分是**账号运营规范**，不是框架代码，需要手动执行规划。

```
资金来源隔离：
  ✅ 从不同 CEX 分别提币到各账号（OKX/Binance/Bybit 混用）
  ✅ 每次提币间隔 1~3 天，不集中批量提
  ❌ 禁止从同一地址给所有账号转账

链上行为去同质化：
  ✅ 不同账号执行顺序随机化（A先swap再checkin，B先checkin再swap）
  ✅ 交互金额随机化（不用固定金额，在合理区间内随机）
  ✅ Gas Price 跟随实时 Gas ±10% 随机浮动
  ❌ 禁止多账号在 ±5 分钟内做完全相同的链上操作

资金归集禁止：
  ❌ 禁止操作完后把所有账号余额转到同一地址（女巫检测最常用手段）
  ✅ 各账号余额独立，长期持有，不集中归集
```

---

### 4.5 Layer 4：状态持久化层

#### SQLite 表结构

```sql
-- 账号状态表
CREATE TABLE accounts (
    id                   TEXT PRIMARY KEY,
    status               TEXT DEFAULT 'active',
    cooldown_until       DATETIME,
    ban_reason           TEXT,
    consecutive_failures INTEGER DEFAULT 0,
    created_at           DATETIME,
    last_active          DATETIME
);

-- 任务执行记录（核心表）
-- status 枚举（唯一真源）：success | failed | skipped | needs_human
-- failure_type 枚举（唯一真源）：network | rate_limited | redesign | account_issue | proxy_fallback | platform_ban
--   可控失败（纳入 SLI）：network | rate_limited | proxy_fallback
--   不可控失败（排除 SLI）：redesign | account_issue | platform_ban
CREATE TABLE task_runs (
    id                   INTEGER PRIMARY KEY AUTOINCREMENT,
    account_id           TEXT,
    task_id              TEXT,
    platform             TEXT,
    started_at           TEXT,    -- UTC ISO-8601，如 "2026-02-19T10:30:00+00:00"
    finished_at          TEXT,    -- UTC ISO-8601
    finished_date_utc    TEXT,    -- ⚠️ YYYY-MM-DD（UTC），由代码写入；should_run_today 用此列过滤，避免 SQLite date() 解析时区坑
    status               TEXT,    -- 见上方枚举注释
    failure_type         TEXT,    -- 见上方枚举注释
    error_msg            TEXT,
    reward_desc          TEXT,
    behavior_profile_id  TEXT,    -- 行为参数版本（来自 global.yaml behavior_profile_id）
    block_policy_id      TEXT,    -- 外键 → request_policies.policy_id，便于按策略统计
    block_policy         TEXT,    -- JSON 原始值，仅调试回溯用
    FOREIGN KEY (account_id) REFERENCES accounts(id),
    FOREIGN KEY (block_policy_id) REFERENCES request_policies(policy_id)
);

-- 代理池状态
CREATE TABLE proxies (
    account_id    TEXT UNIQUE,
    endpoint      TEXT,
    region        TEXT,
    asn           TEXT,           -- 跌落降级时按 ASN 匹配同 ISP 新 IP
    last_verified TEXT,           -- UTC ISO-8601
    is_alive      BOOLEAN DEFAULT TRUE,
    failure_count INTEGER DEFAULT 0
);

-- 代理 IP 跌落事件（追踪 IP 切换历史，用于跌落降级归因）
CREATE TABLE proxy_events (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    account_id  TEXT,
    old_ip      TEXT,
    new_ip      TEXT,
    reason      TEXT,    -- network_timeout | tcp_fail | auth_fail
    switched_at TEXT     -- UTC ISO-8601
);

-- 任务暂停事件（运行时状态，不写 YAML 静态配置）
-- scope_type 枚举：global | account | platform | tag
-- scope_value：NULL（global）| account_id | platform_name | tag_name
--   设计为两列而非单列 scope，支持未来按平台/分组粒度暂停而不破坏 schema
CREATE TABLE task_pause_events (
    id              INTEGER PRIMARY KEY AUTOINCREMENT,
    task_id         TEXT,
    scope_type      TEXT,    -- global | account | platform | tag
    scope_value     TEXT,    -- NULL 表示 global；否则为对应的 account_id/platform/tag 值
    reason          TEXT,
    paused_at       TEXT,    -- UTC ISO-8601
    auto_resume_at  TEXT,    -- UTC ISO-8601，NULL 表示纯人工恢复
    resumed_at      TEXT     -- NULL 表示尚未恢复
);

-- 请求拦截策略维表（block_policy_id 的唯一真源，便于按策略做统计 SQL）
CREATE TABLE request_policies (
    policy_id   TEXT PRIMARY KEY,   -- 如 default_v1 | allow_images_v1 | no_block_v1
    block_types TEXT                -- JSON，如 ["media","font"]
);
-- 初始数据（随代码迁移）：
INSERT INTO request_policies VALUES ('default_v1',       '["media","font"]');
INSERT INTO request_policies VALUES ('allow_images_v1',  '["media","font"]');
INSERT INTO request_policies VALUES ('no_block_v1',      '[]');

-- 每日快照（报表用）
CREATE TABLE daily_summary (
    date            TEXT PRIMARY KEY,   -- UTC 日期，如 "2026-02-19"
    total_accounts  INTEGER,
    active_accounts INTEGER,
    tasks_success   INTEGER,
    tasks_failed    INTEGER,
    tasks_skipped   INTEGER,
    new_bans        INTEGER
);
```

#### 账号状态机

```
         ┌─────────────────────────┐
         │         active          │
         │    正常参与所有调度       │
         └──────┬──────┬───────┘
                │连续失败3次 │ 检测到封禁/账号锁定
                ↓           ↓
         ┌──────────┐  ┌──────────────┐
         │ cooldown │  │  suspended   │
         │ 冷却24h  │  │  等人工审查   │
         └──────┬───┘  └──────┬───────┘
                │冷却到期      │ 确认封禁
                ↓             ↓
         ┌──────────┐  ┌──────────────┐
         │  active  │  │   banned     │
         │  (恢复)   │  │  永久退出调度 │
         └──────────┘  └──────────────┘
```

#### SQLite 并发写入策略

8个浏览器进程并发写入数据库需要明确的并发控制，防止 `database is locked` 错误。

**实现方案：单例连接 + 后台写入队列**

> ⚠️ **修正**：上一版每次 `write()` 都 `aiosqlite.connect()` 新建连接，在 8 并发账号频繁写 `task_runs`/`proxy_events` 时会产生连接抖动，WAL checkpoint 延迟可能将"任务超时"误归为"DB 写入超时"。正确方案：进程内单例连接，所有写操作经 `asyncio.Queue` 序列化。

```python
import asyncio, aiosqlite
from typing import Optional

class StateManager:
    def __init__(self, db_path: str):
        self._db_path = db_path
        self._conn: Optional[aiosqlite.Connection] = None
        self._write_queue: asyncio.Queue = asyncio.Queue()
        self._writer_task: Optional[asyncio.Task] = None

    async def init(self):
        self._conn = await aiosqlite.connect(self._db_path)
        await self._conn.execute("PRAGMA journal_mode=WAL")
        await self._conn.execute("PRAGMA synchronous=NORMAL")
        await self._conn.commit()
        # 后台单 writer task：串行消费写入队列，避免多协程并发写入同一连接
        self._writer_task = asyncio.create_task(self._writer_loop())

    async def _writer_loop(self):
        while True:
            sql, params, fut = await self._write_queue.get()
            if sql is None:          # 哨兵：关闭信号
                break
            try:
                await self._conn.execute(sql, params)
                await self._conn.commit()
                fut.set_result(None)
            except Exception as e:
                fut.set_exception(e)

    async def write(self, sql: str, params: tuple = ()) -> None:
        loop = asyncio.get_running_loop()
        fut: asyncio.Future = loop.create_future()
        await self._write_queue.put((sql, params, fut))
        await fut   # 等待 writer 完成，传播异常

    async def read(self, sql: str, params: tuple = ()) -> list:
        # 读操作用独立连接，WAL 模式允许读写并行，不阻塞写入队列
        async with aiosqlite.connect(self._db_path) as rconn:
            async with rconn.execute(sql, params) as cursor:
                return await cursor.fetchall()

    async def close(self):
        await self._write_queue.put((None, None, None))  # 发送关闭哨兵
        if self._writer_task:
            await self._writer_task
        if self._conn:
            await self._conn.close()
```

> 此方案保持单进程有效（`asyncio.Task` 不跨进程）。读用独立连接，WAL 模式保证读写不阻塞。8 并发账号的写峰值全部序列化到 `_writer_loop`，无连接抖动。`aiosqlite>=0.19.0` 依赖不变。

> ⚠️ **可扩展性边界**：`asyncio.Queue` + 单写 task 仅在单 Python 进程内有效。若未来将调度器改为 `multiprocessing`（多进程）或多机部署，此方案立即失效导致数据库锁死。`StateManager` 应设计为抽象接口，底层可平滑切换到 PostgreSQL：
> ```python
> class BaseStateManager(ABC):
>     @abstractmethod
>     async def write(self, sql: str, params: tuple) -> None: ...
>     @abstractmethod
>     async def read(self, sql: str, params: tuple) -> list: ...
>
> class SQLiteStateManager(BaseStateManager): ...   # 当前实现
> class PostgresStateManager(BaseStateManager): ... # 未来扩展
> ```
> 30-100 账号规模 SQLite 完全够用，但接口抽象今天做，未来迁移成本为零。

---

### 4.6 Layer 5：监控与报告层

#### 每日 Telegram 报告格式

```
📊 每日执行报告 2026-02-19

账号概况：
  活跃账号：87 / 100
  新增冷却：2 个
  新增封禁：0 个 ✅

任务执行：
  总执行次数：261 次
  成功：218 次（83.5%）✅
  失败：28 次（10.7%）
    ├─ 网络超时：15 次
    ├─ 被风控：8 次
    └─ 平台改版：5 次 ⚠️
  跳过（已完成）：15 次

⚠️ 需要人工处理：
  - galxe_daily_checkin 选择器失效（5个账号受影响）
  - acc_034 登录失败，需检查账号状态

收益记录：
  Galxe 积分：+2180 pts（87账号×25pts）
  Layer3 任务：67/87 完成
  Zealy XP：+5350 XP
```

#### 告警触发规则

| 事件 | 触发条件 | 紧急程度 |
|---|---|---|
| 批量封号 | 单天新增封号 ≥ 5 个 | 🔴 立即告警 |
| 平台改版 | 某任务连续3账号失败类型=redesign | 🔴 立即告警 |
| 代理失效 | 某账号代理连续3次验证失败 | 🟡 告警 |
| 任务失败率高 | 某任务成功率 < 50% | 🟡 告警 |
| 每日完成 | 所有批次跑完 | 🟢 常规通知 |

---

## 5. 技术选型决策表

### 5.1 核心工具选型

| 类别 | 选型 | 备选 | 选型理由 |
|---|---|---|---|
| Web2 浏览器引擎 | **Zendriver** | Camoufox（待稳定） | 2025实测75%穿透率，Cloudflare/Akamai双通 |
| Web3 浏览器引擎 | **Playwright + Synpress** | - | MetaMask自动化事实标准，社区活跃 |
| 指纹生成 | **browserforge**（Apify fingerprint-suite Python移植版，v1.2.4） | - | 开源，统计分布真实，最新版2026-02-02，积极维护 |
| 鼠标行为 | **ghost-cursor** | Camoufox内置算法 | 贝塞尔曲线，开源，Playwright生态 |
| 验证码 | **CapSolver** | 2Captcha | 支持Turnstile/hCaptcha/reCAPTCHA，API成熟 |
| 代理 | **Oxylabs住宅IP** | Bright Data / IPRoyal | 粘性会话稳定，地区精准，API管理方便 |
| 数据库 | **SQLite** | PostgreSQL | 零依赖，单文件，30-100账号规模完全够用 |
| 开发语言 | **Python 3.11+** | - | 生态最丰富，Playwright/Zendriver都是Python |
| 任务调度触发 | **APScheduler** | Cron + 系统定时 | Python内嵌，无需外部依赖，支持随机抖动 |
| 告警通知 | **Telegram Bot** | 微信（复杂） | API简单，延迟低，免费 |
| 配置管理 | **YAML + python-dotenv** | - | 可读性好，敏感值用 .env 注入 |

### 5.2 代理选型深度决策

代理是反检测的关键基础设施，也是最大的持续成本项。

| 代理类型 | 穿透能力 | 每GB价格 | 适用场景 | 结论 |
|---|---|---|---|---|
| 住宅IP（Residential） | 高 | $2-5/GB | 常规Web2/Web3任务 | 主力选择 |
| 移动IP（Mobile 4G/5G） | 极高 | $8-15/GB | 极高风控平台 | 高价值任务备用 |
| 数据中心IP（Datacenter） | 低 | $0.3-1/GB | 无 | **禁止使用** |

**粘性会话要求**：每个账号绑定固定IP（sticky session），绑定周期建议 2~4 周（具体时长待实测验证，详见第9节 Open Questions）。频繁切换IP = 触发新设备/新地区检测。

**重要警告（2026最新）**：Cloudflare v8 ML 模型已能识别住宅代理的**行为异常**，不再仅靠IP质量。即使是优质住宅IP，行为模式异常（操作速度、鼠标轨迹）仍会被拦截。**行为模拟比代理质量更重要。**

### 5.3 Web3 钱包管理决策

| 方案 | 安全性 | 自动化难度 | 结论 |
|---|---|---|---|
| MetaMask 扩展（真实） | 高 | 中（Synpress） | ✅ 推荐，最真实 |
| 私钥直签（ethers.js） | 中 | 低 | ⚠️ 仅限纯链上操作，DApp会检测 |
| 硬件钱包 | 极高 | 极高 | ❌ 无法自动化 |
| 种子词热钱包 | 低 | 低 | ❌ 私钥泄露风险极高，禁止 |

结论：DApp 任务必须用真实 MetaMask 扩展；纯链上数据操作（如查询余额、构造裸交易）可以用 ethers.js 直签。

---

## 6. 场景覆盖矩阵

### 6.1 正常运行场景

| 场景 | 处理方式 |
|---|---|
| 账号 Cookie 有效，任务正常执行 | 直接执行，完成后写 DB |
| 今日任务已完成（数据库有记录） | 跳过（status=skipped），不重复执行 |
| 账号在 cooldown 期间 | 调度器跳过，不分配任务 |
| 任务成功但无明确"完成"标志 | 截图保存，状态标记 needs_review |
| 新平台任务插件首次运行 | 同正常流程，额外记录"首次执行"标记 |

### 6.2 异常边界场景

| 场景 | 判断方式 | 处理策略 |
|---|---|---|
| **平台页面改版**（选择器失效） | `ElementNotFound` 异常 | 标记 redesign，告警，暂停该任务所有账号，等人工修复 |
| **网络超时/断线** | `TimeoutError`，HTTP 5xx | 指数退避重试 3 次，3次后标记 network_failed |
| **风控拦截**（Cloudflare challenge） | 出现 challenge 页面 | 尝试 CapSolver，失败则账号冷却24h |
| **验证码出现** | 检测到验证码 DOM | 调用 CapSolver，超时 120s 则暂停等人工 |
| **账号被封**（登录失败且非密码错误） | HTTP 403 / 锁号提示 | 标记 banned，永久退出调度，告警 |
| **代理失效**（IP不可用） | 连接超时 / 代理认证失败 | 验证代理可用性，失败标记代理 is_alive=false，告警 |
| **MetaMask 弹窗未出现**（Web3） | 等待超时 30s | 刷新页面重试一次，仍无则标记失败 |
| **链上交易长时间 pending** | 等待超时 120s | 记录 tx_hash，标记 pending，次日复查 |
| **链上交易 revert** | 交易失败事件 | 记录错误原因，分析是否余额不足或合约问题，告警 |
| **DApp 要求 KYC/人脸** | 检测到人脸识别 DOM | 立即暂停，告警，不能自动处理 |
| **Cookie 在任务中途失效** | 页面跳转到登录页 | 中断任务，重新登录，重试一次 |
| **并发账号被同一IP访问**（代理复用bug） | 检测层：启动前验证IP唯一性 | 启动浏览器前验证代理未被其他进程占用 |

### 6.3 规模性风险场景

| 场景 | 触发条件 | 响应策略 |
|---|---|---|
| **单日大规模封号** | ≥5个账号同日被封 | 立即暂停所有任务，人工审查，查是否有关联泄漏 |
| **平台更新反女巫策略** | 大量账号同时被清除奖励 | 暂停该平台任务，评估继续的价值 |
| **代理商 IP 质量下降** | 成功率突然下降 >20% | 切换备用代理商，老代理继续跑低风险任务 |
| **某批任务全部失败** | 整批 8 账号同一任务全失败 | 暂停该任务，不继续后续批次，人工检查 |

#### "暂停任务"语义精确定义（P2 修复）

> 上表中"暂停"属于高频操作，若不定义精确语义，将出现误暂停一天、忘记恢复等线上事故。

| 属性 | 规范定义 |
|---|---|
| **持久化位置** | DB `task_pause_events` 表（非 tasks.yaml）。tasks.yaml 是静态配置，不应承载运行时状态 |
| **暂停粒度** | `(task_id, scope_type, scope_value)`：scope_type 为 `global`（scope_value=NULL）或 `account`（scope_value=account_id）或 `platform` |
| **触发写入** | `INSERT INTO task_pause_events (task_id, scope_type, scope_value, reason, paused_at, auto_resume_at)` |
| **恢复机制** | ① 人工：`UPDATE task_pause_events SET resumed_at=datetime('now') WHERE task_id=? AND scope_type=? AND scope_value IS ?`；② 自动：`auto_resume_at` 非空时调度器展开时自动检查 |
| **调度器检查** | `should_run_today()` 调用前先查 `task_pause_events`，存在未恢复记录则跳过 |
| **TTL 兜底** | 无 `auto_resume_at` 的全局暂停，72h 后自动发送 Telegram 提醒（防"恢复忘了恢复"） |

```python
# core/state_manager.py — 暂停检测示例
async def is_task_paused(self, task_id: str, account_id: str) -> bool:
    # scope_type/scope_value 双列查询：匹配 global 或指定 account
    rows = await self.read(
        "SELECT 1 FROM task_pause_events "
        "WHERE task_id=? "
        "AND (scope_type='global' OR (scope_type='account' AND scope_value=?)) "
        "AND resumed_at IS NULL "
        "AND (auto_resume_at IS NULL OR auto_resume_at > datetime('now'))",
        (task_id, account_id)
    )
    return len(rows) > 0
```

---

## 7. 边界行为规范

边界行为规范定义：**当系统遇到不确定或高风险情况时，应该做什么、不做什么。**

### 7.1 宁可不做，不做错误的事

| 情况 | 错误行为 | 正确边界行为 |
|---|---|---|
| 不确定任务是否已完成 | 再执行一次（可能触发重复操作检测） | 截图保存，标记 needs_review，跳过 |
| 代理疑似失效 | 继续用本地网络执行 | 中断任务，标记代理失效，等待 |
| 验证码超时未解 | 等待更长时间或强行跳过 | 告警并挂起，等人工处理 |
| 账号登录异常 | 多次尝试登录 | 最多尝试 2 次，失败后标记 suspended |

### 7.2 账号保护红线

以下行为，**框架硬编码禁止**，即使任务插件要求也不执行：

- 禁止同一账号在 4 小时内登录 2 次以上
- 禁止同一账号在 1 小时内完成超过 20 次页面操作
- 禁止同一钱包地址在 1 小时内发送超过 5 笔交易
- 禁止在代理失效（本地IP）的情况下继续执行任务
- 禁止从未经验证的新代理IP立即执行高风险操作（需先"预热"）

### 7.3 代理预热规范

新代理IP不能直接用于高风险操作。必须先"预热"：

```
第1天：仅访问低风险网站（Google、YouTube、Reddit）
第2天：访问目标平台首页，不登录
第3天：登录，不做任何操作
第4天起：正常执行任务
```

### 7.4 任务插件开发边界约束

插件只被允许做以下操作，其余都不允许：
- 页面导航（navigate）
- 元素点击（click）
- 文本输入（type）
- 页面滚动（scroll）
- 等待（wait）
- 读取页面文本（read_text）
- 钱包签名（wallet_sign，通过 Synpress）

插件**不允许**：
- 直接调用 HTTP 请求绕过浏览器
- 注入 JavaScript 到页面（容易被检测）
- 修改账号状态（必须通过框架API）
- 访问其他账号的配置或 Cookie

> ⚠️ **P0 执行约束**：以上"不允许"是口头约定，没有运行时 enforce。任何插件作者都可以 `import requests`、`import os`、`open(secrets/...)` 而框架毫无感知。这是最容易翻车的安全/一致性缺口。**必须有 enforce 机制**。

#### 插件执行隔离方案（诚实说明现状 + 可落地路径）

> ⚠️ **重要更正**：下面"声明式 Steps"示例中，插件仍是**任意 Python 模块**——即使 `get_steps()` 只返回 Steps 列表，import 时仍可执行任意代码（读 secrets、发网络请求）。这是 **API 约定**，不是 enforce。请在选型时清醒认知。

**方案 A（当前可落地，API 约定层）：声明式 Steps**

定义 `Step` 数据结构，插件通过 `get_steps()` 返回步骤列表，框架 dispatch 执行。**主进程仍然 import 插件代码**，无法防止 import 阶段副作用：

```python
# core/plugin_api.py
from dataclasses import dataclass
from typing import List, Union

@dataclass
class Navigate:   url: str
@dataclass
class Click:      selector: str
@dataclass
class Type:       selector: str; text: str
@dataclass
class Scroll:     times: int = 1
@dataclass
class WaitRandom: min_s: float; max_s: float
@dataclass
class ReadText:   selector: str; store_as: str
@dataclass
class WalletSign: pass

Step = Union[Navigate, Click, Type, Scroll, WaitRandom, ReadText, WalletSign]

# plugins/web2/galxe_checkin.py
def get_steps(account: dict, ctx: dict) -> List[Step]:
    return [
        Navigate(url="https://galxe.com/..."),
        Scroll(times=2),
        WaitRandom(min_s=1.5, max_s=4.0),
        Click(selector="button[data-testid='checkin']"),
    ]
```

**方案 B（真正 enforce，子进程加载）**：主进程**不 import 插件**，而是以子进程启动 plugin runner，仅通过 IPC（stdin/stdout）传递 steps 列表：

```
主进程 (scheduler)
    → asyncio.create_subprocess_exec(["python", "plugin_runner.py", "--plugin", "galxe_checkin"])
    → stdin: JSON { account_id, ctx }
    → plugin_runner.py: import plugin, call get_steps(), return JSON steps to stdout
    → 主进程收到 steps JSON，dispatch 执行（主进程不 import 插件代码）
```

**方案 A/B 迁移触发条件（可执行）**

| 触发条件 | 动作 |
|---|---|
| 出现一次插件越权事故（读到 secrets/、发网络请求） | 立即切 B，官测全部插件 |
| 插件作者 ≥ 3 人（外包或团队协作） | 切 B |
| 需要在 CI/CD 流水线执行不可信插件 | 切 B |
| 安全审计要求（SOC2/内控） | 切 B |
| 插件超过 15 个且有外部贡献者 | 切 B |

**当前文档选方案 A**，明确标注：所有插件须经代码 review 方可合入。上表任一条成立时必须切 B。

> **条件分支局限**：`get_steps()` 不支持"如果按钮A不存在则点B"的运行时条件判断。复杂逻辑通过 `PluginContext.query(selector) -> bool` 接口在 dispatch 层实现，插件仅声明条件键，框架负责查询和分支。

---

## 8. 风险矩阵

### 8.1 技术风险

| 风险 | 概率 | 影响 | 缓解措施 |
|---|---|---|---|
| Zendriver 被主流平台新增检测 | 中 | 高 | 监控成功率，准备 Camoufox 切换方案 |
| Camoufox 维护缺口导致指纹暴露 | 中 | 高 | 当前主力用 Zendriver，Camoufox 作备选 |
| 代理商 IP 质量下降 | 中 | 中 | 多代理商备份，定期验证 IP 质量 |
| Synpress 与新版 MetaMask 不兼容 | 低 | 高 | 固定 MetaMask 版本，监控 Synpress 更新 |
| SQLite 并发写入冲突 | 低 | 低 | 使用 WAL 模式，写入加锁 |

### 8.2 运营风险

| 风险 | 概率 | 影响 | 缓解措施 |
|---|---|---|---|
| 单次批量封号（关联检测） | 中 | 极高 | 严格隔离，错峰执行，批次≤8 |
| 平台改版脚本失效 | 高 | 中 | 告警机制，插件化便于快速修复 |
| 私钥/凭据泄露 | 低 | 极高 | secrets/ 不进 Git，加密存储，最小权限 |
| 平台主动女巫清查 | 高（Web3） | 高 | 链上行为去同质化，资金来源多样化 |
| 打码服务不可用 | 低 | 中 | 多服务备份，人工兜底通道 |

### 8.3 合规边界

本框架设计用于**合法的活动参与自动化**，不用于：
- 欺诈、洗钱等违法活动
- 攻击或破坏平台服务
- 大规模薅取不符合规则的奖励

每个平台的使用条款对多账号的态度不同，**用户自行判断和承担相应风险**。

---

## 9. 未解决的开放问题（Open Questions）

这些问题在设计阶段尚未有定论，需要在 MVP 阶段通过实验得出答案：

| 问题 | 影响 | 当前假设 | 需要验证的方式 |
|---|---|---|---|
| Zendriver + browserforge 组合在 Galxe 上的实际成功率？ | 高 | 估计 70-80% | 10账号跑1周，统计成功率 |
| MetaMask 版本固定在哪个版本最稳定？ | 中 | v12.x | Synpress 兼容性测试 |
| 粘性代理 IP 应该绑定多久？ | 中 | 2-4周 | 对比不同周期的封号率 |
| Cookie 平均有效期是多久（各平台）？ | 中 | 7-30天 | 实测记录，按平台建立经验值 |
| 代理预热需要多久？ | 中 | 4天 | A/B测试预热vs不预热的封号率 |
| 30账号 vs 100账号时，最优批次大小是否改变？ | 低 | 保持8 | 逐步扩量时观察 |
| Web3平台 Sybil 清查周期是多久？ | 高 | 项目快发币前 | 持续观察各项目公告 |

---

## 10. 实施路线图

### Phase 0（第1周）：环境与基础设施
- [ ] 搭建项目目录结构
- [ ] 配置 Python 虚拟环境，安装 Zendriver / Playwright / Synpress
- [ ] 购买并验证第一个住宅代理账号（5个IP）
- [ ] 建立 SQLite 数据库表结构
- [ ] 配置 Telegram Bot 告警
- [ ] 编写第一个账号配置文件（acc_001.yaml）

### Phase 1（第2-3周）：单账号 MVP
- [ ] 实现 browser_factory.py（Web2分支，Zendriver+指纹注入）
- [ ] 实现 base_task.py（TaskPlugin 基类）
- [ ] 写第一个任务插件（选最简单的：Zealy签到 或 Galxe每日任务）
- [ ] 实现 state_manager.py（SQLite读写）
- [ ] 端到端跑通：1账号 → 1任务 → 结果写DB

**验收**：1账号稳定跑 3 天，成功率 ≥ 80%，pixelscan.net 指纹检测通过

### Phase 2（第4-5周）：10账号调度
- [ ] 实现 scheduler.py（顺序调度 + 随机延迟）
- [ ] 实现 reporter.py（每日报告 + Telegram推送）
- [ ] 扩展到 10 个账号配置
- [ ] 加入第2个任务插件（不同平台）
- [ ] Cookie持久化机制上线

**验收**：10账号并发，任务成功率 ≥ 75%，无关联封号

### Phase 3（第6-8周）：30-50账号 + Web3
- [ ] 实现 browser_factory.py Web3分支（Playwright + Synpress + MetaMask）
- [ ] 实现第一个 Web3 任务插件（Galxe钱包连接任务）
- [ ] 并发控制优化（max 8，批次错峰）
- [ ] 账号状态机完整实现
- [ ] 代理池管理（自动验证可用性）

**验收**：50账号稳定运行 1 周，无批量封号事件

### Phase 4（第9-12周）：满规模优化
- [ ] 扩展到 80-100 账号
- [ ] 失败自愈机制（选择器更新辅助）
- [ ] 监控看板（本地 Web UI）
- [ ] 性能调优（内存/进程管理）

---

*文档版本：v1.6 | 最后更新：2026-02-19 | 下一步：Phase 0 环境搭建*

---

## 附录A：胶水层组合方案（各开源组件集成细节）

### A.1 核心思路：你写翻译层，不造轮子

```
你写的胶水代码（~630行Python + ~200行TypeScript）
        ↓ 调用
┌──────────────────────────────────────────────────────────┐
│  zendriver          → 启动反检测Chrome，传入代理+指纹     │
│  browserforge       → 生成统计一致的指纹参数（Python版）  │
│  python-ghost-cursor→ 贝塞尔曲线鼠标移动                 │
│  Synpress（Node.js）→ MetaMask弹窗自动化                 │
│  APScheduler        → 定时触发+随机抖动                  │
│  SQLite（内置）      → 状态持久化                        │
│  python-telegram-bot→ 告警推送                          │
└──────────────────────────────────────────────────────────┘
```

你的代码只做**翻译和编排**：把账号配置翻译成各库的调用参数，把各库结果翻译成统一状态写入DB。

---

### A.2 各组件集成接口

#### zendriver（Web2浏览器引擎）

```python
import zendriver as zd

async def launch_web2_browser(account: Account) -> zd.Browser:
    fp = account.fingerprint
    browser = await zd.start(
        browser_args=[
            f"--proxy-server=socks5://{account.proxy.endpoint}",
            f"--lang={fp.language}",
            f"--window-size={fp.screen}",
        ],
        user_data_dir=f"data/profiles/web2/{account.id}",  # 独立Cookie隔离
        headless=False,
    )
    return browser
```

你写的胶水：把 `account.yaml` 里的字段翻译成 `browser_args`。**约30行**。

#### browserforge（指纹生成，Python版）

```python
from browserforge.fingerprints import FingerprintGenerator, Screen

gen = FingerprintGenerator(
    browser="chrome",
    os="windows",
    screen=Screen(min_width=1280, max_width=1920),
)
fp = gen.generate()
# fp.navigator.user_agent / fp.screen.width / fp.navigator.languages ...
```

账号首次创建时调用一次，结果序列化存进账号YAML，之后固定不变。**约20行**。

#### python-ghost-cursor（鼠标行为）

```python
from python_ghost_cursor.playwright_async import create_cursor

# 封装在 base_task.py 里，插件直接调 self.click(selector)
async def click(self, page, selector: str):
    cursor = create_cursor(page)
    await page.wait_for_selector(selector)
    await cursor.click(selector)  # 贝塞尔曲线移动后点击
```

在 `BaseTask` 里封装，插件不感知 ghost-cursor 的存在。**约15行**。

#### Synpress（Web3 MetaMask）— Python调Node.js子进程

**已确定方案**：Python调Node.js子进程，跨语言但各自最优。

```
Python调度层
    → asyncio.create_subprocess_exec(["node", "plugin.js", "--account", "acc_001"])
    → 敏感参数（params + parent_pid）通过 stdin 管道传入（ps aux 不可见）
    → Node.js 从 stdin 读配置，用 Synpress 操作 MetaMask
    → 结果写 stdout（JSON格式）
    → Python 读取 stdout，解析结果，写 DB
    → 超时则 proc.kill() + proc.communicate() 强制回收，防僵尸进程
```

Python侧胶水（`core/web3_bridge.py`）：
```python
import os, json, asyncio

async def run_web3_plugin(account_id: str, plugin_name: str, params: dict = {}) -> dict:
    cmd = ["node", f"plugins/web3/{plugin_name}.js", "--account", account_id]
    stdin_payload = json.dumps({
        "params": params,
        "parent_pid": os.getpid(),   # Node 侧监听父进程，父挂则子自退
    }).encode()

    proc = await asyncio.create_subprocess_exec(
        *cmd,
        stdin=asyncio.subprocess.PIPE,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE,
    )
    try:
        stdout, stderr = await asyncio.wait_for(
            proc.communicate(input=stdin_payload), timeout=300
        )
    except asyncio.TimeoutError:
        proc.kill()
        await proc.communicate()         # 强制回收，防止僵尸进程
        raise RuntimeError(f"Web3 plugin timed out (300s): {plugin_name}")

    if proc.returncode != 0:
        raise RuntimeError(f"Web3 plugin failed: {stderr.decode()}")

    raw = stdout.decode()
    # 进程间协议：Node 侧结果固定在最后一行以 __RESULT__ 前缀输出，其余行视为日志
    result_line = next(
        (ln for ln in reversed(raw.splitlines()) if ln.startswith("__RESULT__")),
        None,
    )
    if result_line is None:
        raise RuntimeError(f"Web3 plugin: no __RESULT__ line in stdout: {raw[-300:]!r}")
    try:
        return json.loads(result_line[len("__RESULT__"):])
    except json.JSONDecodeError as e:
        raise RuntimeError(f"Web3 plugin: malformed __RESULT__ line: {result_line[:200]!r}") from e
```

Node.js插件模板（`plugins/web3/galxe_checkin.js`）：
```typescript
import { chromium } from '@playwright/test'
import { MetaMask } from '@synthetixio/synpress/playwright'
import * as fs from 'fs'
import * as yaml from 'js-yaml'  // ✅ YAML 必须用 js-yaml 解析，不能 JSON.parse

const accountId = process.argv[process.argv.indexOf('--account') + 1]
// ✅ 用 js-yaml 解析 YAML 配置文件（JSON.parse 无法解析 YAML，会直接 throw）
const config = yaml.load(fs.readFileSync(`config/accounts/${accountId}.yaml`, 'utf8')) as Record<string, any>

// ✅ 从 stdin 读取敏感参数，不经过 CLI args（ps aux 不可见）
const stdinPayload: { params: Record<string, unknown>; parent_pid: number } =
  await new Promise((resolve) => {
    let buf = ''
    process.stdin.setEncoding('utf8')
    process.stdin.on('data', (c) => (buf += c))
    process.stdin.on('end', () => resolve(JSON.parse(buf)))
  })

// watchdog：每 3s 向 Python 侧的 stdin pipe 写心跳；Python 停止读则 write 报错，子进程自退
// ⚠️ 注意：process.kill(pid, 0) 有 PID 复用风险，生产场景应改为 stdin 管道心跳
const watchdog = setInterval(() => {
  try { process.stdout.write('') } // 探测管道是否仍然连通（管道关闭时会 throw）
  catch { clearInterval(watchdog); process.exit(1) }
}, 3000)

async function main() {
  const browser = await chromium.launchPersistentContext(
    `data/metamask_profiles/${accountId}`,
    { headless: false, args: [`--proxy-server=socks5://${config.proxy.endpoint}`] }
  )
  const page = await browser.newPage()

  // 请求拦截：任务级策略覆写，从 stdinPayload.params.block_resources 读取
  // 全局默认阻断 ['media','font']，图片由各任务插件按需决定是否放行
  const blockTypes: string[] = (stdinPayload.params.block_resources as string[]) ?? ['media', 'font']
  await page.route('**/*', (route) => {
    if (blockTypes.includes(route.request().resourceType())) {
      route.abort()
    } else {
      route.continue()
    }
  })

  const metamask = new MetaMask(browser, /* metamaskPage */, config.wallets.evm.password)
  await page.goto('https://galxe.com/...')
  await metamask.connectToDapp()
  await metamask.confirmSignature()

  clearInterval(watchdog)
  // ✅ 进程间协议：结果必须以 __RESULT__ 前缀写到最后一行，其余 console.log 视为日志
  console.log('__RESULT__' + JSON.stringify({ status: 'success', reward: 'Galxe 25pts' }))
  await browser.close()
}

main().catch(e => {
  clearInterval(watchdog)
  console.error(e.message)
  process.exit(1)
})
```

Python侧胶水约**50行**，每个Node.js插件约**80-120行TypeScript**。

---

### A.3 完整依赖清单

**Python（requirements.txt）**：
```
zendriver>=0.15.2
browserforge>=1.2.4
python-ghost-cursor>=0.1.1
APScheduler>=3.10.0
pyyaml>=6.0
pydantic>=2.0
python-dotenv>=1.0
python-telegram-bot>=21.0
aiofiles>=23.0
aiosqlite>=0.19.0
cryptography>=42.0
capsolver>=2.0.0            # PyPI 包名：capsolver（非 capsolver-extension-python）
                             # pip install capsolver；https://pypi.org/project/capsolver/
```

**Node.js（package.json）**：
```json
{
  "dependencies": {
    "@synthetixio/synpress": "^4.0.5",
    "@playwright/test": "^1.40.0",
    "js-yaml": "^4.1.0"
  }
}
```

---

### A.4 胶水代码量估算

| 模块 | 你写的代码 | 调用的库 |
|---|---|---|
| `browser_factory.py` | ~80行 | zendriver + browserforge |
| `behavior.py` | ~60行 | python-ghost-cursor + 自定义延迟 |
| `scheduler.py` | ~100行 | APScheduler |
| `state_manager.py` | ~120行 | sqlite3（内置） |
| `account.py` | ~60行 | pyyaml + pydantic |
| `base_task.py` | ~80行 | 纯Python |
| `reporter.py` | ~80行 | python-telegram-bot |
| `web3_bridge.py` | ~50行 | subprocess/asyncio |
| **Python合计** | **~630行** | 全部开源免费 |
| 每个Web3插件 | ~100行TypeScript | Synpress + Playwright |

---

## 附录B：框架能力与开源组件对应表

| 框架能力 | 由谁实现 | 你写的胶水 |
|---|---|---|
| **账号生命周期管理** | `pydantic`（数据模型）+ `pyyaml`（配置读取）+ `SQLite`（状态持久化） | `account.py` + `state_manager.py`，你定义状态机转换逻辑 |
| **任务调度** | `APScheduler`（定时触发）+ `asyncio`（并发控制） | `scheduler.py`，你写批次分组、随机打乱、指数退避重试逻辑 |
| **浏览器执行**（反检测+指纹+代理+隔离） | `zendriver`（反检测Chrome）+ `browserforge`（指纹生成）+ 独立`user_data_dir`（Cookie隔离） | `browser_factory.py`，你把账号配置翻译成启动参数 |
| **Web2任务执行** | `zendriver`（操作API）+ `python-ghost-cursor`（鼠标）+ `CapSolver`（验证码） | `base_task.py`，封装`click/type/scroll`，插件调这些方法 |
| **Web3任务执行** | `Synpress`（MetaMask弹窗）+ `Playwright`（Chrome控制），Node.js侧 | `web3_bridge.py`，Python调Node.js子进程，传参+读JSON结果 |
| **状态持久化** | `SQLite`（内置，零依赖） | `state_manager.py`，你定义表结构和读写接口 |
| **结果报告** | `python-telegram-bot`（推送）+ SQLite聚合查询 | `reporter.py`，你写SQL统计和消息格式化 |
| **插件机制** | 纯Python抽象类（无需第三方库） | `base_task.py`里的`TaskPlugin`抽象基类，你定义接口规范 |

### 关键点总结

**没有任何一个能力是"开箱即用"的**——每个能力都需要你写胶水代码把库连起来。但每个能力的**核心难点**都有开源库解决了：

- 反检测难点（TLS指纹、CDP检测）→ zendriver 解决
- 指纹一致性难点（canvas/webgl/audio统计分布）→ browserforge 解决
- 鼠标行为难点（贝塞尔曲线）→ ghost-cursor 解决
- MetaMask弹窗难点（扩展页面控制）→ Synpress 解决
- 定时随机调度难点 → APScheduler 的 `jitter` 参数解决

**你写的是编排逻辑**，不是底层实现。这就是"胶水层"的本质。

---

*文档版本：v1.7 | 更新：2026-02-19 第三轮工程审计修复（P0）：SQLite date()时区坑修复（新增finished_date_utc列，should_run_today改为TEXT=TEXT精确匹配）、task_pause_events.scope拆为scope_type+scope_value双列（支持future platform/tag粒度）、StateManager改为单例连接+后台asyncio.Queue写入序列化（消除连接抖动）；（P1）：插件A→B迁移触发条件表（可执行判断）、status/failure_type枚举唯一真源+SLI SQL参考实现（3条标准查询）、block_policy_id外键+request_policies维表；（P2）：标题/尾部版本号统一为v1.6→v1.7、capsolver PyPI包名修正并锁版本*
